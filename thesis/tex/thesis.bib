@inproceedings{alselekAgileAIFirmware2024,
  title = {Agile {{AI}} and {{Firmware Management}} in {{IoT}}: {{DevOps}} for {{Low-Power Microcontroller-Based Platforms}}},
  shorttitle = {Agile {{AI}} and {{Firmware Management}} in {{IoT}}},
  booktitle = {2024 9th {{International Conference}} on {{Smart}} and {{Sustainable Technologies}} ({{SpliTech}})},
  author = {AlSelek, Mohammad and {Alcaraz-Calero}, Jose M. and Wang, Qi},
  year = {2024},
  month = jun,
  pages = {1--6},
  doi = {10.23919/SpliTech61897.2024.10612585},
  urldate = {2024-12-16},
  abstract = {In this paper, we introduce a Development and Operations (DevOps)-based IoT system tailored for the dynamic management of firmware and AI models across distributed IoT environments. The system offers scalability, resource efficiency, and cost-effectiveness for updating the AI model and firmware on the IoT devices without a need for human intervention. To accomplish this, we have developed a continuous integration and continuous deployment (CI/CD) pipelines that operate across multiple platforms, leveraging the capabilities of Kubernetes and GitLab-Runner. Moreover, the system is specifically designed for Microcontroller-based low-power devices capable of running tiny AI models. The new deployment is sent to the IoT devices despite their location to start interacting with the surrounding environment and perform predictions regarding its application. Through empirical experiments, we demonstrate the system effectiveness with promising results in terms of scalability, resource utilization, and deployment efficiency.},
  keywords = {Adaptation models,AI,Biological system modeling,CT: Framework,DevOps,GitLab,Internet of Things,IoT,Kubernetes,Microcontroller,Micropython,Microservices,Performance evaluation,Pipelines,RT: Solution Paper,Scalability},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/AlSelek et al. - 2024 - Agile AI and Firmware Management in IoT DevOps for Low-Power Microcontroller-Based Platforms.docx;/Users/lukasgrodmeier/Zotero/storage/8DXC9DJM/AlSelek et al. - 2024 - Agile AI and Firmware Management in IoT DevOps for Low-Power Microcontroller-Based Platforms.pdf}
}

@article{alselekDynamicAIIoTEnabling2024,
  title = {Dynamic {{AI-IoT}}: {{Enabling Updatable AI Models}} in {{Ultralow-Power 5G IoT Devices}}},
  shorttitle = {Dynamic {{AI-IoT}}},
  author = {AlSelek, Mohammad and {Alcaraz-Calero}, Jose M. and Wang, Qi},
  year = {2024},
  month = apr,
  journal = {IEEE Internet of Things Journal},
  volume = {11},
  number = {8},
  pages = {14192--14205},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3340858},
  urldate = {2024-12-16},
  abstract = {This article addresses the challenge of integrating dynamic AI capabilities into ultralow-power (ULP) IoT devices, a critical necessity in the rapidly evolving landscape of 5G and potential 6G technologies. We introduce the Dynamic AI-IoT architecture, a novel framework designed to eliminate the need for cumbersome firmware updates. This architecture leverages Narrowband IoT (NB-IoT) to facilitate smooth cloud interactions and incorporates tailored firmware extensions for enabling dynamic interactions with Tiny Machine Learning (TinyML) models. A sophisticated memory management mechanism, grounded in memory alignment and dynamic AI operations resolution, is introduced to efficiently handle AI tasks. Empirical experiments demonstrate the feasibility of implementing a Dynamic AI-IoT system using ULP IoT devices on a 5G testbed. The results show model updates taking less than one second and an average inference time of approximately 46 ms.},
  keywords = {5G,5G mobile communication,Adaptation models,artificial intelligence,Artificial intelligence,Computational modeling,CT: Framework,ESP32,Fipy,Internet of Things,Load modeling,micropython,Narrowband IoT (NB-IoT),Power demand,Pysense,RT: Solution Paper,Tensorflow},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/AlSelek et al. - 2024 - Dynamic AI-IoT Enabling Updatable AI Models in Ultralow-Power 5G IoT Devices.docx;/Users/lukasgrodmeier/Zotero/storage/7PHF8M8X/AlSelek et al. - 2024 - Dynamic AI-IoT Enabling Updatable AI Models in Ultralow-Power 5G IoT Devices.pdf}
}

@inproceedings{amounajafabadiAnalysisMLOpsArchitectures2024,
  title = {An {{Analysis}} of~{{MLOps Architectures}}: {{A Systematic Mapping Study}}},
  shorttitle = {An {{Analysis}} of~{{MLOps Architectures}}},
  booktitle = {Software {{Architecture}}},
  author = {Amou Najafabadi, Faezeh and Bogner, Justus and Gerostathopoulos, Ilias and Lago, Patricia},
  editor = {Galster, Matthias and Scandurra, Patrizia and Mikkonen, Tommi and Oliveira Antonino, Pablo and Nakagawa, Elisa Yumi and Navarro, Elena},
  year = {2024},
  pages = {69--85},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-70797-1_5},
  abstract = {Context. Despite the increasing adoption of Machine Learning Operations (MLOps), teams still encounter challenges in effectively applying this paradigm to their specific projects. While there is a large variety of available tools usable for MLOps, there is simultaneously a lack of consolidated architecture knowledge that can inform the architecture design.Objective. Our primary objective is to provide a comprehensive overview of (i) how MLOps architectures are defined across the literature and (ii) which tools are mentioned to support the implementation of each architecture component. Method. We apply the Systematic Mapping Study method and select 43 primary studies via automatic, manual, and snowballing-based search and selection procedures. Subsequently, we use card sorting to synthesize the results. Results. We contribute (i) a categorization of 35 MLOps architecture components, (ii) a description of several MLOps architecture variants, and (iii) a systematic map between the identified components and the existing MLOps tools. Conclusion. This study provides an overview of the state of the art in MLOps from an architectural perspective. Researchers and practitioners can use our findings to inform the architecture design of their MLOps systems.},
  isbn = {978-3-031-70797-1},
  langid = {english},
  keywords = {Architecture,Components,Machine Learning Operations,MLOps,Systematic Mapping Study,Tools},
  file = {/Users/lukasgrodmeier/Zotero/storage/6EMRIHCZ/Amou Najafabadi et al. - 2024 - An Analysis of MLOps Architectures A Systematic Mapping Study.pdf;/Users/lukasgrodmeier/Zotero/storage/LPF422XJ/2406.19847v1.pdf}
}

@inproceedings{antoniniTinyMLOpsFrameworkOrchestrating2022,
  title = {Tiny-{{MLOps}}: A Framework for Orchestrating {{ML}} Applications at the Far Edge of {{IoT}} Systems},
  shorttitle = {Tiny-{{MLOps}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Evolving}} and {{Adaptive Intelligent Systems}} ({{EAIS}})},
  author = {Antonini, Mattia and Pincheira, Miguel and Vecchio, Massimo and Antonelli, Fabio},
  year = {2022},
  month = may,
  pages = {1--8},
  issn = {2473-4691},
  doi = {10.1109/EAIS51927.2022.9787703},
  urldate = {2024-12-07},
  abstract = {Empowering the Internet of Things devices with Artificial Intelligence capabilities can transform all vertical applications domains within the next few years. Current approaches favor hosting Machine Learning (ML) models on Linux-based single-board computers. Nevertheless, these devices' cost and energy requirements limit the possible application scenarios. Conversely, today's available 32-bit microcontrollers have much lower costs and only need a few milliwatts to operate, making them an energy-efficient and cost-effective alternative. However, the latter devices, usually referred to as far edge devices, have stringent resource constraints and host non-Linux-based embedded real-time operating systems. Therefore, orchestrating such devices executing portions of ML applications represents a major challenge with current tools and frameworks. This paper formally introduces the Tiny-MLOps framework as the specialization of standard ML orchestration practices, including far edge devices in the loop. To this aim, we will tailor each phase of the classical ML orchestration loop to the reduced resources available onboard typical IoT devices. We will rely on the proposed framework to deliver adaptation and evolving capabilities to resource-constrained IoT sensors mounted on an industrial rotary machine to detect anomalies. As a feasibility study, We will show how to programmatically re-deploy ML-based anomaly detection models to far edge devices. Our preliminary experiments measuring the system performance in terms of deployment, loading, and inference latency of the ML models will corroborate the usefulness of our proposal.},
  keywords = {Adaptation models,Costs,CT: Framework,Image edge detection,Real-time systems,RT: Solution Paper,Sensors,System performance,Transforms},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Antonini et al. - 2022 - Tiny-MLOps a framework for orchestrating ML applications at the far edge of IoT systems.docx;/Users/lukasgrodmeier/Zotero/storage/Y6UTNRTF/Antonini et al. - 2022 - Tiny-MLOps a framework for orchestrating ML applications at the far edge of IoT systems.pdf}
}

@article{azevedoDetectingFaceMasks2023a,
  title = {Detecting Face Masks through Embedded Machine Learning Algorithms: {{A}} Transfer Learning Approach for Affordable Microcontrollers},
  shorttitle = {Detecting Face Masks through Embedded Machine Learning Algorithms},
  author = {Azevedo, Mariana B. and {de Medeiros}, Tha{\'i}s de A. and Medeiros, Morsinaldo de A. and Silva, Ivanovitch and Costa, Daniel G.},
  year = {2023},
  month = dec,
  journal = {Machine Learning with Applications},
  volume = {14},
  pages = {100498},
  issn = {2666-8270},
  doi = {10.1016/j.mlwa.2023.100498},
  urldate = {2024-12-13},
  abstract = {The adoption of face masks to halt the spread of airborne diseases has been recognized as an effective measure, being a significant resource to reduce new infections of different types of virus that affect the respiratory system. In this sense, the enforcement of the use of masks in crowded areas has been a recurrent concern of governments, which has fostered the development of camera-based approaches to automatically detect people without face masks. In order to tackle this problem, this article proposes a low-cost approach based on the use of affordable and energy-efficient microcontrollers to quickly process images and detect when people are not wearing face masks, performing local decisions. For this on-the-edge processing, reduced Machine Learning models were created and evaluated through different techniques. As a result, a complete processing pipeline was designed to perform a transfer learning process taking as reference the MobileNet model supported by the Edge Impulse platform, achieving an innovative TinyML solution for quick decisions on resource-constrained Internet of Things units. Additionally, we performed a series of experiments on the Arduino Nano 33 board attached to an OV7675 camera module, evaluating the practical application of the proposed solution after proper training using public image datasets. Working as a soft-sensor unit that is reproducible and ready to be used, the defined trainable model and the performed evaluation results represent a significant contribution towards real-world deployment of face masks detection systems.},
  keywords = {Edge computing,Embedded Machine Learning,Mask detection,TinyML,Transfer Learning},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Azevedo et al. - 2023 - Detecting face masks through embedded machine learning algorithms A transfer learning approach for.docx;/Users/lukasgrodmeier/Zotero/storage/ZWGY9ZN2/Azevedo et al. - 2023 - Detecting face masks through embedded machine learning algorithms A transfer learning approach for.pdf}
}

@misc{banburyBenchmarkingTinyMLSystems2021,
  title = {Benchmarking {{TinyML Systems}}: {{Challenges}} and {{Direction}}},
  shorttitle = {Benchmarking {{TinyML Systems}}},
  author = {Banbury, Colby R. and Reddi, Vijay Janapa and Lam, Max and Fu, William and Fazel, Amin and Holleman, Jeremy and Huang, Xinyuan and Hurtado, Robert and Kanter, David and Lokhmotov, Anton and Patterson, David and Pau, Danilo and Seo, Jae-sun and Sieracki, Jeff and Thakker, Urmish and Verhelst, Marian and Yadav, Poonam},
  year = {2021},
  month = jan,
  number = {arXiv:2003.04821},
  eprint = {2003.04821},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2003.04821},
  urldate = {2025-02-08},
  abstract = {Recent advancements in ultra-low-power machine learning (TinyML) hardware promises to unlock an entirely new class of smart applications. However, continued progress is limited by the lack of a widely accepted benchmark for these systems. Benchmarking allows us to measure and thereby systematically compare, evaluate, and improve the performance of systems and is therefore fundamental to a field reaching maturity. In this position paper, we present the current landscape of TinyML and discuss the challenges and direction towards developing a fair and useful hardware benchmark for TinyML workloads. Furthermore, we present our four benchmarks and discuss our selection methodology. Our viewpoints reflect the collective thoughts of the TinyMLPerf working group that is comprised of over 30 organizations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Performance},
  file = {/Users/lukasgrodmeier/Zotero/storage/PKUV8LJD/Banbury et al. - 2021 - Benchmarking TinyML Systems Challenges and Direction.pdf;/Users/lukasgrodmeier/Zotero/storage/33N2ZRZ5/2003.html}
}

@article{banburyEdgeImpulseMLOps2023,
  title = {Edge {{Impulse}}: {{An MLOps Platform}} for {{Tiny Machine Learning}}},
  shorttitle = {Edge {{Impulse}}},
  author = {Banbury, Colby and Janapa Reddi, Vijay and Elium, Alexander and Hymel, Shawn and Tischler, David and Situnayake, Daniel and Ward, Carl and Moreau, Louis and Plunkett, Jenny and Kelcey, Matthew and Baaijens, Mathijs and Grande, Alessandro and Maslov, Dmitry and Beavis, Arthur and Jongboom, Jan and Quaye, Jessica},
  year = {2023},
  month = mar,
  journal = {Proceedings of Machine Learning and Systems},
  volume = {5},
  pages = {254--268},
  urldate = {2024-12-07},
  langid = {english},
  keywords = {CT: Tool,RT: Evaluation Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Banbury et al. - 2023 - Edge Impulse An MLOps Platform for Tiny Machine Learning.docx;/Users/lukasgrodmeier/Zotero/storage/SHU3VVJD/Banbury et al. - 2023 - Edge Impulse An MLOps Platform for Tiny Machine Learning.pdf}
}

@article{brancoMachineLearningResourceScarce2019,
  title = {Machine {{Learning}} in {{Resource-Scarce Embedded Systems}}, {{FPGAs}}, and {{End-Devices}}: {{A Survey}}},
  shorttitle = {Machine {{Learning}} in {{Resource-Scarce Embedded Systems}}, {{FPGAs}}, and {{End-Devices}}},
  author = {Branco, S{\'e}rgio and Ferreira, Andr{\'e} G. and Cabral, Jorge},
  year = {2019},
  month = nov,
  journal = {Electronics},
  volume = {8},
  number = {11},
  pages = {1289},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics8111289},
  urldate = {2025-02-08},
  abstract = {The number of devices connected to the Internet is increasing, exchanging large amounts of data, and turning the Internet into the 21st-century silk road for data. This road has taken machine learning to new areas of applications. However, machine learning models are not yet seen as complex systems that must run in powerful computers (i.e., Cloud). As technology, techniques, and algorithms advance, these models are implemented into more computational constrained devices. The following paper presents a study about the optimizations, algorithms, and platforms used to implement such models into the network's end, where highly resource-scarce microcontroller units (MCUs) are found. The paper aims to provide guidelines, taxonomies, concepts, and future directions to help decentralize the network's intelligence.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {embedded systems,end-devices,FPGA,machine learning,resource-scarce MCUs},
  file = {/Users/lukasgrodmeier/Zotero/storage/I3MH5MSY/Branco et al. - 2019 - Machine Learning in Resource-Scarce Embedded Systems, FPGAs, and End-Devices A Survey.pdf}
}

@article{burgueno-romeroOpenSourceMLOps2025,
  title = {Toward an {{Open Source MLOps Architecture}}},
  author = {{Burgue{\~n}o-Romero}, Antonio M. and {Ben{\'i}tez-Hidalgo}, Antonio and {Barba-Gonz{\'a}lez}, Crist{\'o}bal and {Aldana-Montes}, Jos{\'e} F.},
  year = {2025},
  month = jan,
  journal = {IEEE Software},
  volume = {42},
  number = {1},
  pages = {59--64},
  issn = {1937-4194},
  doi = {10.1109/MS.2024.3421675},
  urldate = {2024-12-07},
  abstract = {We present a Kubernetes-based, open source MLOps framework to streamline the lifecycle management of machine learning models in production environments. We compared state-of-the-art MLOps tools and frameworks, demonstrating that ours meets the same features as proprietary options, such as Amazon SageMaker.},
  keywords = {Computer architecture,Life cycle assessment,Machine learning,Monitoring,Open source software,Predictive models,Production systems,Python,Software testing},
  file = {/Users/lukasgrodmeier/Zotero/storage/YJXK9J6V/Burgueño-Romero et al. - 2025 - Toward an Open Source MLOps Architecture.pdf}
}

@article{capogrossoMachineLearningOrientedSurvey2024,
  title = {A {{Machine Learning-Oriented Survey}} on {{Tiny Machine Learning}}},
  author = {Capogrosso, Luigi and Cunico, Federico and Cheng, Dong Seon and Fummi, Franco and Cristani, Marco},
  year = {2024},
  journal = {IEEE Access},
  volume = {12},
  pages = {23406--23426},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3365349},
  urldate = {2024-12-07},
  abstract = {The emergence of Tiny Machine Learning (TinyML) has positively revolutionized the field of Artificial Intelligence by promoting the joint design of resource-constrained IoT hardware devices and their learning-based software architectures. TinyML carries an essential role within the fourth and fifth industrial revolutions in helping societies, economies, and individuals employ effective AI-infused computing technologies (e.g., smart cities, automotive, and medical robotics). Given its multidisciplinary nature, the field of TinyML has been approached from many different angles: this comprehensive survey wishes to provide an up-to-date overview focused on all the learning algorithms within TinyML-based solutions. The survey is based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow, allowing for a systematic and complete literature survey. In particular, firstly, we will examine the three different workflows for implementing a TinyML-based system, i.e., ML-oriented, HW-oriented, and co-design. Secondly, we propose a taxonomy that covers the learning panorama under the TinyML lens, examining in detail the different families of model optimization and design, as well as the state-of-the-art learning techniques. Thirdly, this survey will present the distinct features of hardware devices and software tools that represent the current state-of-the-art for TinyML intelligent edge applications. Finally, we discuss the challenges and future directions.},
  keywords = {Anomaly detection,Artificial intelligence,Benchmark testing,Computational modeling,Deep learning,Edge computing,edge intelligence,efficient deep learning,embedded systems,Embedded systems,Hardware,Internet of Things,Machine learning,Micromachining,Surveys,Systematics,TinyML,Training},
  file = {/Users/lukasgrodmeier/Zotero/storage/NWXBN8QJ/Capogrosso et al. - 2024 - A Machine Learning-Oriented Survey on Tiny Machine Learning.pdf}
}

@article{chandolaAnomalyDetectionSurvey2009,
  title = {Anomaly Detection: {{A}} Survey},
  shorttitle = {Anomaly Detection},
  author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  year = {2009},
  month = jul,
  journal = {ACM Computing Surveys},
  volume = {41},
  number = {3},
  pages = {1--58},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/1541880.1541882},
  urldate = {2025-05-22},
  abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/38ZCBU65/Chandola et al. - 2009 - Anomaly detection A survey.pdf}
}

@article{changSurveyRecentAdvances2021,
  title = {A {{Survey}} of {{Recent Advances}} in {{Edge-Computing-Powered Artificial Intelligence}} of {{Things}}},
  author = {Chang, Zhuoqing and Liu, Shubo and Xiong, Xingxing and Cai, Zhaohui and Tu, Guoqing},
  year = {2021},
  month = sep,
  journal = {IEEE Internet of Things Journal},
  volume = {8},
  number = {18},
  pages = {13849--13875},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2021.3088875},
  urldate = {2024-12-12},
  abstract = {The Internet of Things (IoT) has created a ubiquitously connected world powered by a multitude of wired and wireless sensors generating a variety of heterogeneous data over time in a myriad of fields and applications. To extract complete information from these data, advanced artificial intelligence (AI) technology, especially deep learning (DL), has proved successful in facilitating data analytics, future prediction and decision making. The collective integration of AI and the IoT has greatly promoted the rapid development of AI-of-Things (AIoT) systems that analyze and respond to external stimuli more intelligently without involvement by humans. However, it is challenging or infeasible to process massive amounts of data in the cloud due to the destructive impact of the volume, velocity, and veracity of data and fatal transmission latency on networking infrastructures. These critical challenges can be adequately addressed by introducing edge computing. This article conducts an extensive survey of an end-edge-cloud orchestrated architecture for flexible AIoT systems. Specifically, it begins with articulating fundamental concepts including the IoT, AI and edge computing. Guided by these concepts, it explores the general AIoT architecture, presents a practical AIoT example to illustrate how AI can be applied in real-world applications and summarizes promising AIoT applications. Then, the emerging technologies for AI models regarding inference and training at the edge of the network are reviewed. Finally, the open challenges and future directions in this promising area are outlined.},
  keywords = {Artificial intelligence,Artificial intelligence (AI),Cloud computing,Computational modeling,Computer architecture,deep learning (DL),edge computing,Edge computing,Internet of Things,Internet of Things (IoT),machine learning (ML),Training},
  file = {/Users/lukasgrodmeier/Zotero/storage/9K9D9Q7G/Chang et al. - 2021 - A Survey of Recent Advances in Edge-Computing-Powered Artificial Intelligence of Things.pdf}
}

@article{cliffDominanceStatisticsOrdinal1993,
  title = {Dominance Statistics: {{Ordinal}} Analyses to Answer Ordinal Questions},
  shorttitle = {Dominance Statistics},
  author = {Cliff, Norman},
  year = {1993},
  journal = {Psychological Bulletin},
  volume = {114},
  number = {3},
  pages = {494--509},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.114.3.494},
  abstract = {Much behavioral research involves comparing the central tendencies of different groups, or of the same Ss under different conditions, and the usual analysis is some form of mean comparison. This article suggests that an ordinal statistic, d, is often more appropriate. d compares the number of times a score from one group or condition is higher than one from the other, compared with the reverse. Compared to mean comparisons, d is more robust and equally or more powerful; it is invariant under transformation; and it often conforms more closely to the experimeter's research hypothesis. It is suggested that inferences from d be based on sample estimates of its variance rather than on the more traditional assumption of identical distributions. The statistic is extended to simple repeated measures designs, and ways of extending its use to more complex designs are suggested. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Statistical Analysis},
  file = {/Users/lukasgrodmeier/Zotero/storage/W5MRRPBS/1994-08169-001.html}
}

@book{cohenStatisticalPowerAnalysis2009,
  title = {Statistical Power Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob},
  year = {2009},
  edition = {2. ed., reprint},
  publisher = {Psychology Press},
  address = {New York, NY},
  isbn = {978-0-8058-0283-2},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/Z5XCHYNR/Cohen - 2009 - Statistical power analysis for the behavioral sciences.pdf}
}

@article{condeEnhancedFIWAREBasedArchitecture2024,
  title = {Enhanced {{FIWARE-Based Architecture}} for {{Cyberphysical Systems With Tiny Machine Learning}} and {{Machine Learning Operations}}: {{A Case Study}} on {{Urban Mobility Systems}}},
  shorttitle = {Enhanced {{FIWARE-Based Architecture}} for {{Cyberphysical Systems With Tiny Machine Learning}} and {{Machine Learning Operations}}},
  author = {Conde, Javier and {Munoz-Arcentales}, Andr{\'e}s and Alonso, {\'A}lvaro and Salvach{\'u}a, Joaqu{\'i}n and Huecas, Gabriel},
  year = {2024},
  month = sep,
  journal = {IT Professional},
  volume = {26},
  number = {5},
  pages = {55--61},
  issn = {1941-045X},
  doi = {10.1109/MITP.2024.3421968},
  urldate = {2024-12-16},
  abstract = {The rise of AI and the Internet of Things is accelerating the digital transformation of society. Mobility computing presents specific barriers due to its real-time requirements, decentralization, and connectivity through wireless networks. New research on edge computing and tiny machine learning (tinyML) explores the execution of AI models on low-performance devices to address these issues. However, there are not many studies proposing agnostic architectures that manage the entire lifecycle of intelligent cyberphysical systems. This article extends a previous architecture based on FIWARE software components to implement the machine learning operations flow, enabling the management of the entire tinyML lifecycle in cyberphysical systems. We also provide a use case to showcase how to implement the FIWARE architecture through a complete example of a smart traffic system. We conclude that the FIWARE ecosystem constitutes a real reference option for developing tinyML and edge computing in cyberphysical systems.},
  keywords = {Computer architecture,CT: Framework,Cyber-physical systems,Digital transformation,Ecosystems,Edge computing,Internet of Things,Real-time systems,RT: Solution Paper,Software,Tiny machine learning,Wireless networks},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Conde et al. - 2024 - Enhanced FIWARE-Based Architecture for Cyberphysical Systems With Tiny Machine Learning and Machine.docx;/Users/lukasgrodmeier/Zotero/storage/YYT96KHR/Conde et al. - 2024 - Enhanced FIWARE-Based Architecture for Cyberphysical Systems With Tiny Machine Learning and Machine.pdf}
}

@article{davidTensorFlowLiteMicro2021,
  title = {{{TensorFlow Lite Micro}}: {{Embedded Machine Learning}} for {{TinyML Systems}}},
  shorttitle = {{{TensorFlow Lite Micro}}},
  author = {David, Robert and Duke, Jared and Jain, Advait and Janapa Reddi, Vijay and Jeffries, Nat and Li, Jian and Kreeger, Nick and Nappier, Ian and Natraj, Meghna and Wang, Tiezhen and Warden, Pete and Rhodes, Rocky},
  year = {2021},
  month = mar,
  journal = {Proceedings of Machine Learning and Systems},
  volume = {3},
  pages = {800--811},
  urldate = {2024-12-07},
  langid = {english},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/David et al. - 2021 - TensorFlow Lite Micro Embedded Machine Learning for TinyML Systems.docx;/Users/lukasgrodmeier/Zotero/storage/Q8QGV8JR/David et al. - 2021 - TensorFlow Lite Micro Embedded Machine Learning for TinyML Systems.pdf}
}

@inproceedings{demaghSensOLMemoryEfficientOnline2024,
  title = {{{SensOL}}: {{Memory-Efficient Online Learning}} for {{Tiny MCUs}}},
  shorttitle = {{{SensOL}}},
  booktitle = {2024 {{IEEE SENSORS}}},
  author = {Demagh, Lokmane and Garda, Patrick and Gilbert, Cedric and Hachicha, Khalil},
  year = {2024},
  month = oct,
  pages = {1--4},
  issn = {2168-9229},
  doi = {10.1109/SENSORS60989.2024.10784905},
  urldate = {2025-01-04},
  abstract = {This paper introduces SensOL, an online learning replay-based approach for hardware-limited microcontroller units (MCUs). It addresses two major bottlenecks for continuous learning within tiny MCUs: the computational cost of learning a new task in real time and the memory requirements for storing task exemplars. Our proposal originally combines the TinyOL approach with a memory-efficient replay strategy to refresh old task information during the continuous training process. The memory footprint for storing task exemplars is optimized by saving the quantized outputs of the frozen model, which are subsequently compressed according to their sparsity level. We evaluated our approach on a realistic online incremental IMU-based transport mode learning scenario. The SensOL approach demonstrated a 115x lower memory footprint for storing the compressed task exemplars compared to storing them in their original format. Finally, we estimated the on-device training time to update the weights/biases and achieved a time of 1 ms within an STM32L476JGY microcontroller based on an Arm Cortex-M4 processor operating at 80 MHz.},
  keywords = {CT: Framework,Incremental learning,Intelligent sensors,Low latency communication,Memory management,Microcontrollers,online learning,Proposals,Real-time systems,RT: Solution Paper,Sensor systems,tinyml,Training,transport mode detection,Vectors,wearable smart sensing},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Demagh et al. - 2024 - SensOL Memory-Efficient Online Learning for Tiny MCUs.docx;/Users/lukasgrodmeier/Zotero/storage/7F9FT3DY/Demagh et al. - 2024 - SensOL Memory-Efficient Online Learning for Tiny MCUs.pdf}
}

@article{diaz-de-arcayaJointStudyChallenges2024,
  title = {A {{Joint Study}} of the {{Challenges}}, {{Opportunities}}, and {{Roadmap}} of {{MLOps}} and {{AIOps}}: {{A Systematic Survey}}},
  shorttitle = {A {{Joint Study}} of the {{Challenges}}, {{Opportunities}}, and {{Roadmap}} of {{MLOps}} and {{AIOps}}},
  author = {{Diaz-de-Arcaya}, Josu and {Torre-Bastida}, Ana I. and Z{\'a}rate, Gorka and Mi{\~n}{\'o}n, Ra{\'u}l and Almeida, Aitor},
  year = {2024},
  month = apr,
  journal = {ACM Computing Surveys},
  volume = {56},
  number = {4},
  pages = {1--30},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3625289},
  urldate = {2024-12-16},
  abstract = {Data science projects represent a greater challenge than software engineering for organizations pursuing their adoption. The diverse stakeholders involved emphasize the need for a collaborative culture in organizations. This article aims to offer joint insights into the role of MLOps and AIOps methodologies for raising the success of data science projects in various fields, ranging from pure research to more traditional industries. We analyze the open issues, opportunities, and future trends organizations face when implementing MLOps and AIOps. Then, the frameworks and architectures that promote these paradigms are presented, as are the different fields in which they are being utilized. This systematic review was conducted using an automated procedure that identified 44,903 records, which were filtered down to 93 studies. These articles are meant to better clarify the problem at hand and highlight the future areas in both research and industry in which MLOPs and AIOps are thriving. Our findings indicate that AIOps flourish in challenging circumstances like those presented by 5G and 6G technologies, whereas MLOps is more prevalent in traditional industrial environments. The use of AIOps in certain stages of the ML lifecycle, such as deployment, remains underrepresented in scientific literature.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/CDE8M76L/Diaz-de-Arcaya et al. - 2024 - A Joint Study of the Challenges, Opportunities, and Roadmap of MLOps and AIOps A Systematic Survey.pdf}
}

@inproceedings{disabatoIncrementalOnDeviceTiny2020,
  title = {Incremental {{On-Device Tiny Machine Learning}}},
  booktitle = {Proceedings of the 2nd {{International Workshop}} on {{Challenges}} in {{Artificial Intelligence}} and {{Machine Learning}} for {{Internet}} of {{Things}}},
  author = {Disabato, Simone and Roveri, Manuel},
  year = {2020},
  month = nov,
  series = {{{AIChallengeIoT}} '20},
  pages = {7--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3417313.3429378},
  urldate = {2024-12-16},
  abstract = {Tiny Machine Learning (TML) is a novel research area aiming at designing and developing Machine Learning (ML) techniques meant to be executed on Embedded Systems and Internet-of-Things (IoT) units. Such techniques, which take into account the constraints on computation, memory, and energy characterizing the hardware platform they operate on, exploit approximation and pruning mechanisms to reduce the computational load and the memory demand of Machine and Deep Learning (DL) algorithms.Despite the advancement of the research, TML solutions present in the literature assume that Embedded Systems and IoT units support only the inference of ML and DL algorithms, whereas their training is confined to more-powerful computing units (due to larger computational load and memory demand). This also prevents such pervasive devices from being able to learn in an incremental way directly from the field to improve the accuracy over time or to adapt to new working conditions.The aim of this paper is to address such an open challenge by introducing an incremental algorithm based on transfer learning and k-nearest neighbor to support the on-device learning (and not only the inference) of ML and DL solutions on embedded systems and IoT units. Moreover, the proposed solution is general and can be applied to different application scenarios. Experimental results on image/audio benchmarks and two off-the-shelf hardware platforms show the feasibility and effectiveness of the proposed solution.},
  isbn = {978-1-4503-8134-5},
  keywords = {CT: Framework,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Disabato und Roveri - 2020 - Incremental On-Device Tiny Machine Learning.docx;/Users/lukasgrodmeier/Zotero/storage/Q5HHUUG4/Disabato und Roveri - 2020 - Incremental On-Device Tiny Machine Learning.pdf}
}

@article{disabatoTinyMachineLearning2024,
  title = {Tiny {{Machine Learning}} for {{Concept Drift}}},
  author = {Disabato, Simone and Roveri, Manuel},
  year = {2024},
  month = jun,
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {35},
  number = {6},
  pages = {8470--8481},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2022.3229897},
  urldate = {2025-01-05},
  abstract = {Tiny machine learning (TML) is a new research area whose goal is to design machine and deep learning (DL) techniques able to operate in embedded systems and the Internet-of-Things (IoT) units, hence satisfying the severe technological constraints on memory, computation, and energy characterizing these pervasive devices. Interestingly, the related literature mainly focused on reducing the computational and memory demand of the inference phase of machine and deep learning models. At the same time, the training is typically assumed to be carried out in cloud or edge computing systems (due to the larger memory and computational requirements). This assumption results in TML solutions that might become obsolete when the process generating the data is affected by concept drift (e.g., due to periodicity or seasonality effect, faults or malfunctioning affecting sensors or actuators, or changes in the users' behavior), a common situation in real-world application scenarios. For the first time in the literature, this article introduces a TML for concept drift (TML-CD) solution based on deep learning feature extractors and a k -nearest neighbors ( k -NNs) classifier integrating a hybrid adaptation module able to deal with concept drift affecting the data-generating process. This adaptation module continuously updates (in a passive way) the knowledge base of TML-CD and, at the same time, employs a change detection test (CDT) to inspect for changes (in an active way) to quickly adapt to concept drift by removing obsolete knowledge. Experimental results on both image and audio benchmarks show the effectiveness of the proposed solution, whilst the porting of TML-CD on three off-the-shelf micro-controller units (MCUs) shows the feasibility of what is proposed in real-world pervasive systems.},
  keywords = {Adaptation,concept drift,CT: Framework,Deep learning,deep learning (DL),Embedded systems,Feature extraction,k-nearest neighbor (k-NN),Learning systems,Machine learning,Memory management,RT: Solution Paper,tiny machine learning (TML),Training},
  file = {/Users/lukasgrodmeier/Zotero/storage/S997ANEV/Disabato und Roveri - 2024 - Tiny Machine Learning for Concept Drift.pdf;/Users/lukasgrodmeier/Zotero/storage/XBHUCP9H/9999257.html}
}

@inproceedings{doyuTinyMLaaSEcosystemMachine2021,
  title = {A {{TinyMLaaS Ecosystem}} for {{Machine Learning}} in {{IoT}}: {{Overview}} and {{Research Challenges}}},
  shorttitle = {A {{TinyMLaaS Ecosystem}} for {{Machine Learning}} in {{IoT}}},
  booktitle = {2021 {{International Symposium}} on {{VLSI Design}}, {{Automation}} and {{Test}} ({{VLSI-DAT}})},
  author = {Doyu, Hiroshi and Morabito, Roberto and Brachmann, Martina},
  year = {2021},
  month = apr,
  pages = {1--5},
  issn = {2472-9124},
  doi = {10.1109/VLSI-DAT52063.2021.9427352},
  urldate = {2024-12-07},
  abstract = {Tiny Machine Learning (TinyML) is an emerging concept that concerns the execution of ML tasks on very constrained IoT devices. Although TinyML has generated a strong R\&D interest around it, various challenges limit its effective execution in the constrained devices world, with the result of slowing down the development of a complete ecosystem around it. TinyML as-a-Service (TinyMLaaS) aims to fill the gap in this respect, with the definition of a set of guidelines that can enable an easier democratization of TinyML. In this paper, we describe how the "as-a-Service" model is bound to TinyML, by providing an overview of our concept and introducing the design requirements and building blocks that can make TinyMLaaS reality.},
  keywords = {CT: Guideline,Design automation,Ecosystems,Guidelines,Machine learning,Research and development,RT: Philosophical Paper,Task analysis,Very large scale integration},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Doyu et al. - 2021 - A TinyMLaaS Ecosystem for Machine Learning in IoT Overview and Research Challenges.docx;/Users/lukasgrodmeier/Zotero/storage/TS7CIHDE/Doyu et al. - 2021 - A TinyMLaaS Ecosystem for Machine Learning in IoT Overview and Research Challenges.pdf}
}

@article{duttaTinyMLMeetsIoT2021,
  title = {{{TinyML Meets IoT}}: {{A Comprehensive Survey}}},
  shorttitle = {{{TinyML Meets IoT}}},
  author = {Dutta, Dr. Lachit and Bharali, Swapna},
  year = {2021},
  month = dec,
  journal = {Internet of Things},
  volume = {16},
  pages = {100461},
  issn = {2542-6605},
  doi = {10.1016/j.iot.2021.100461},
  urldate = {2024-12-07},
  abstract = {The rapid growth in miniaturization of low-power embedded devices and advancement in the optimization of machine learning (ML) algorithms have opened up a new prospect of the Internet of Things (IoT), tiny machine learning (TinyML), which calls for implementing the ML algorithm within the IoT device. TinyML framework in IoT is aimed to provide low latency, effective bandwidth utilization, strengthen data safety, enhance privacy, and reduce cost. Its ability to empower the IoT device to reliably function without consistent access to the cloud services while delivering accurate ML services makes it a promising option for IoT applications seeking cost-effective solutions. Especially in settings where inadequate connectivity is common, TinyML aims to provide on-premise analytics which will add substantial benefit to IoT services. In this article, we introduce the definition of TinyML and provide background information on diverse related technologies stating their strengths and weaknesses. We then show how TinyML-as-a-service is implemented through efficient hardware-software co-design. This article also introduces the role of 5G in TinyML-IoT scenario. Furthermore, it touches on the recent progress in TinyML research in both academia and industry along with future challenges and opportunities. We believe that this review will serve as an information cornerstone for the IoT research community and pave the way for further research in this direction.},
  keywords = {hardware-software co-design,Internet of Things (IoT),tiny machine learning (TinyML)},
  file = {/Users/lukasgrodmeier/Zotero/storage/8FHTGND8/Dutta und Bharali - 2021 - TinyML Meets IoT A Comprehensive Survey.pdf}
}

@article{floresAdvancingTinyMLOpsRobust2024a,
  title = {Advancing {{TinyMLOps}}: {{Robust Model Updates}} in the {{Internet}} of {{Intelligent Vehicles}}},
  shorttitle = {Advancing {{TinyMLOps}}},
  author = {Flores, Thommas K. S. and Silva, Ivanovitch and Azevedo, Mariana B. and {de Medeiros}, Thais de A. and Medeiros, Morsinaldo de A. and Costa, Daniel G. and Ferrari, Paolo and Sisinni, Emiliano},
  year = {2024},
  journal = {IEEE Micro},
  pages = {1--12},
  issn = {1937-4143},
  doi = {10.1109/MM.2024.3354323},
  urldate = {2024-12-13},
  abstract = {The Internet of Intelligent Vehicles is becoming increasingly important, and embedded machine learning is gaining popularity due to new development paradigms. However, the demand for machine learning model updates on embedded systems has become relevant in multiple scenarios. This article proposes a methodology for TinyMLOps within the context of the Internet of Intelligent Vehicles, utilizing affordable microcontrollers based on the ESP32 platform. The solution presented in the article consists of two ESP32 devices: one functioning as a Radio Station (RS) and the other as the microcontroller of an On-Board Diagnostic (OBD-II) scanner. The RS hosts the updated model and transmits it to the OBD-II scanner using the ESP-NOW communication protocol over 802.11 Wi-Fi. Experimental results demonstrate significant improvement in model performance post-update, but the article also identifies critical challenges to model robustness because of the use of the interpreter method on microcontrollers.},
  keywords = {Atmospheric modeling,CT: Framework,Data models,Hardware,Machine learning,Mathematical models,Performance evaluation,RT: Validation Research,Training},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Flores et al. - 2024 - Advancing TinyMLOps Robust Model Updates in the Internet of Intelligent Vehicles.docx;/Users/lukasgrodmeier/Zotero/storage/WN8772NX/Flores et al. - 2024 - Advancing TinyMLOps Robust Model Updates in the Internet of Intelligent Vehicles.pdf}
}

@inproceedings{fraidlingTinyMachineLearning2023,
  title = {Tiny {{Machine Learning Sensor Platform}} for {{Local Sensor Data Fusion}} and {{Evaluation}}},
  booktitle = {{{MikroSystemTechnik Kongress}} 2023; {{Kongress}}},
  author = {Fraidling, Florens and Hochreiter, Christian and Heinrich, Ferdinand and Rieger, Florian and Wenninger, Franz},
  year = {2023},
  month = oct,
  pages = {714--721},
  urldate = {2024-12-07},
  abstract = {Cunently prevalent methods for analyzing sensor data rely on centralized processing. The transmission of collected sensor data leads to increased latency, and applications could additionally suffer from bandwidth constraints and privacy concerns. On-device data analysis is crucial for many future edge computing applications. Embedded machine learning is an increasingly important approach to enable local sensor data analysis on resource constrained edge devices. This paper demonstrates a concrete implementation of the embedded machine learning life cycle on the developed Tiny Machine Learning Sensor Platform to enable local sensor data fusion and evaluation for generic applications. The featured Tiny Machine Learning Sensor Platform exhibits cormnon microcontroller interfaces to attach generic sensors suitable for domain-specific applications in a wide range of use cases. It is intended for time series domain specific task such as anomaly detection, classification and prediction. The platform runs machine learning models and neural networks that are specifically optimized for resource constrained embedded microcontrollers. The advantage of on-device data analysis is that the sensor platform itself can decide locally how to proceed when the deployed machine learning model detects certain events. Data only needs to be transmitted to a centralized service when an event has occuned. The device does not need to constantly send its monitored data when there is little or no new information reducing the amount of data transmitted significantly and allowing extended run times of battery-powered systems. The platfonn can react autonomously to specific events without waiting for a server response, reducing the latency for real-time, safety critical applications. This paper describes the applied hardware, software, and the data science pipeline used to develop machine learning enhanced applications on embedded hardware. A first version of the Tiny Machine Learning Sensor Platform is already deployed in several applications. It is planned to adapt the Tiny Machine Learning Sensor Platform to additional use cases and further develop identified challenges. In summary, the practicability of tiny machine learning in real world time series data applications is demonstrated.},
  isbn = {978-3-8007-6203-3},
  keywords = {CT: Framework,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Fraidling et al. - 2023 - Tiny Machine Learning Sensor Platform for Local Sensor Data Fusion and Evaluation.docx;/Users/lukasgrodmeier/Zotero/storage/WZY2M86K/Fraidling et al. - 2023 - Tiny Machine Learning Sensor Platform for Local Sensor Data Fusion and Evaluation.pdf}
}

@article{gamaSurveyConceptDrift2014,
  title = {A Survey on Concept Drift Adaptation},
  author = {Gama, Jo{\~a}o and {\v Z}liobait{\.e}, Indr{\.e} and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
  year = {2014},
  month = apr,
  journal = {ACM Computing Surveys},
  volume = {46},
  number = {4},
  pages = {1--37},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/2523813},
  urldate = {2025-05-22},
  abstract = {Concept drift primarily refers to an online supervised learning scenario when the relation between the input data and the target variable changes over time. Assuming a general knowledge of supervised learning in this article, we characterize adaptive learning processes; categorize existing strategies for handling concept drift; overview the most representative, distinct, and popular techniques and algorithms; discuss evaluation methodology of adaptive algorithms; and present a set of illustrative applications. The survey covers the different facets of concept drift in an integrated way to reflect on the existing scattered state of the art. Thus, it aims at providing a comprehensive introduction to the concept drift adaptation for researchers, industry analysts, and practitioners.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/HJUCRWXD/Gama et al. - 2014 - A survey on concept drift adaptation.pdf}
}

@article{gillEdgeAITaxonomy2024,
  title = {Edge {{AI}}: {{A Taxonomy}}, {{Systematic Review}} and {{Future Directions}}},
  shorttitle = {Edge {{AI}}},
  author = {Gill, Sukhpal Singh and Golec, Muhammed and Hu, Jianmin and Xu, Minxian and Du, Junhui and Wu, Huaming and Walia, Guneet Kaur and Murugesan, Subramaniam Subramanian and Ali, Babar and Kumar, Mohit and Ye, Kejiang and Verma, Prabal and Kumar, Surendra and Cuadrado, Felix and Uhlig, Steve},
  year = {2024},
  month = oct,
  journal = {Cluster Computing},
  volume = {28},
  number = {1},
  pages = {18},
  issn = {1573-7543},
  doi = {10.1007/s10586-024-04686-y},
  urldate = {2025-01-04},
  abstract = {Edge Artificial Intelligence (AI) incorporates a network of interconnected systems and devices that receive, cache, process, and analyse data in close communication with the location where the data is captured with AI technology. Recent advancements in AI efficiency, the widespread use of Internet of Things (IoT) devices, and the emergence of edge computing have unlocked the enormous scope of Edge AI. The goal of Edge AI is to optimize data processing efficiency and velocity while ensuring data confidentiality and integrity. Despite being a relatively new field of research, spanning from 2014 to the present, it has shown significant and rapid development over the last five years. In this article, we present a systematic literature review for Edge AI to discuss the existing research, recent advancements, and future research directions. We created a collaborative edge AI learning system for cloud and edge computing analysis, including an in-depth study of the architectures that facilitate this mechanism. The taxonomy for Edge AI facilitates the classification and configuration of Edge AI systems while also examining its potential influence across many fields through compassing infrastructure, cloud computing, fog computing, services, use cases, ML and deep learning, and resource management. This study highlights the significance of Edge AI in processing real-time data at the edge of the network. Additionally, it emphasizes the research challenges encountered by Edge AI systems, including constraints on resources, vulnerabilities to security threats, and problems with scalability. Finally, this study highlights the potential future research directions that aim to address the current limitations of Edge AI by providing innovative solutions.},
  langid = {english},
  keywords = {Artificial intelligence,Artificial Intelligence,Cloud computing,Edge AI,Edge computing,Machine learning},
  file = {/Users/lukasgrodmeier/Zotero/storage/KNAWHTUB/Gill et al. - 2024 - Edge AI A Taxonomy, Systematic Review and Future Directions.pdf}
}

@inproceedings{grauOnDeviceTrainingMachine2021,
  title = {On-{{Device Training}} of {{Machine Learning Models}} on {{Microcontrollers With}} a {{Look}} at {{Federated Learning}}},
  booktitle = {Proceedings of the {{Conference}} on {{Information Technology}} for {{Social Good}}},
  author = {Grau, Marc Monfort and Centelles, Roger Pueyo and Freitag, Felix},
  year = {2021},
  month = sep,
  series = {{{GoodIT}} '21},
  pages = {198--203},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3462203.3475896},
  urldate = {2024-12-16},
  abstract = {Recent progress in machine learning frameworks makes it now possible to run an inference with sophisticated machine learning models on tiny microcontrollers. Model training, however, is typically done separately on powerful computers. There, the training process has abundant CPU and memory resources to process the stored datasets. In this work, we explore a different approach: training the model directly on the microcontroller. We implement this approach for a keyword spotting task. Then, we extend the training process using federated learning among microcontrollers. Our experiments with model training show an overall trend of decreasing loss with the increase of training epochs.},
  isbn = {978-1-4503-8478-0},
  keywords = {CT: Framework,RT: Validation Research},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Grau et al. - 2021 - On-Device Training of Machine Learning Models on Microcontrollers With a Look at Federated Learning.docx;/Users/lukasgrodmeier/Zotero/storage/ZBU4VP3U/Grau et al. - 2021 - On-Device Training of Machine Learning Models on Microcontrollers With a Look at Federated Learning.pdf}
}

@article{gulatiTDMiLTinyDistributed2024,
  title = {{{TDMiL}}: {{Tiny Distributed Machine Learning}} for {{Microcontroller-Based Interconnected Devices}}},
  shorttitle = {{{TDMiL}}},
  author = {Gulati, Mayank and Zandberg, Koen and Huang, Zhaolan and Wunder, Gerhard and Adjih, Cedric and Baccelli, Emmanuel},
  year = {2024},
  journal = {IEEE Access},
  volume = {12},
  pages = {167810--167826},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3492921},
  urldate = {2024-12-16},
  abstract = {More and more, edge devices embark Artificial Neuron Networks. In this context, a trend is to simultaneously decentralize their training as much as possible while shrinking their resource requirements, both for inference and training---tasks that are typically intensive in terms of data, memory, and computation. At the edge's extremity, a specific challenge arises concerning the inclusion of microcontroller-based devices typically deployed in the IoT. So far, no general framework has been provided for that. Such devices not only have extremely challenging resource constraints (weak CPUs, slow network connections, memory budgets measured in kilobytes) but also exhibit high polymorphism, leading to large variability in computational performance among these devices. In this paper, we design and implement TDMiL, a versatile framework for distributed training, and transfer learning. TDMiL interconnects and combines logical components including CoAPerator (a central aggregator) and various tiny embedded software runtimes that are specifically tailored for networks comprising heterogeneous, resource-constrained devices built on diverse types of microcontrollers. We report on experiments conducted with the TDMiL framework, which we use to comparatively evaluate several schemes devised to address computational variability among distributed learning microcontroller-based devices, i.e., stragglers. Additionally, we release the code of our implementation of TDMiL as an open-source project, which is compatible with common commercial off-the-shelf IoT hardware and a well-known open-access IoT testbed.},
  keywords = {Computer aided instruction,CT: Framework,Data models,Distance learning,Distributed computing,Distributed learning,Federated learning,federated learning (FL),Internet of Things,Internet of Things (IoT),machine learning,Machine learning,microcontrollers,Microcontrollers,Protocols,RT: Validation Research,Tiny machine learning,TinyML-as-a-Service (TMLaaS),Training,Transfer learning},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Gulati et al. - 2024 - TDMiL Tiny Distributed Machine Learning for Microcontroller-Based Interconnected Devices.docx;/Users/lukasgrodmeier/Zotero/storage/Z8DP7TU9/Gulati et al. - 2024 - TDMiL Tiny Distributed Machine Learning for Microcontroller-Based Interconnected Devices.pdf}
}

@incollection{hevnerDesignScienceResearch2010a,
  title = {Design {{Science Research}} in {{Information Systems}}},
  booktitle = {Design {{Research}} in {{Information Systems}}: {{Theory}} and {{Practice}}},
  author = {Hevner, Alan and Chatterjee, Samir},
  editor = {Hevner, Alan and Chatterjee, Samir},
  year = {2010},
  pages = {9--22},
  publisher = {Springer US},
  address = {Boston, MA},
  doi = {10.1007/978-1-4419-5653-8_2},
  urldate = {2024-12-22},
  abstract = {Design activities are central to most applied disciplines. Research in design has a long history in many fields including architecture, engineering, education, psychology, and the fine arts (Cross 2001). The computing and information technology (CIT) field since its advent in the late 1940s has appropriated many of the ideas, concepts, and methods of design science that have originated in these other disciplines. However, information systems (IS) as composed of inherently mutable and adaptable hardware, software, and human interfaces provide many unique and challenging design problems that call for new and creative ideas.},
  isbn = {978-1-4419-5653-8},
  langid = {english},
  keywords = {Design Cycle,Design Science,Group Decision Support System,Information System,Research Cycle}
}

@article{huangRIOTMLToolkitOvertheair2024a,
  title = {{{RIOT-ML}}: Toolkit for over-the-Air Secure Updates and Performance Evaluation of {{TinyML}} Models},
  shorttitle = {{{RIOT-ML}}},
  author = {Huang, Zhaolan and Zandberg, Koen and Schleiser, Kaspar and Baccelli, Emmanuel},
  year = {2024},
  month = may,
  journal = {Annals of Telecommunications},
  issn = {1958-9395},
  doi = {10.1007/s12243-024-01041-5},
  urldate = {2024-12-13},
  abstract = {Practitioners in the field of TinyML lack so far a comprehensive, ``batteries-included'' toolkit to streamline continuous integration, continuous deployment and performance assessments of executing diverse machine learning models on various low-power IoT hardware. Addressing this gap, our paper introduces RIOT-ML, a versatile toolkit crafted to assist IoT designers and researchers in these tasks. To this end, we designed RIOT-ML based on an integration of an array of functionalities from a low-power embedded OS, a universal model transpiler and compiler, a toolkit for TinyML performance measurement, and a low-power over-the-air secure update framework---all of which usable on an open-access IoT testbed available to the community. Our open-source implementation of RIOT-ML and the initial experiments we report on showcase its utility in experimentally evaluating TinyML model performance across fleets of low-power IoT boards under test in the field, featuring a wide spectrum of heterogeneous microcontroller architectures and fleet network connectivity configurations. The existence of an open-source toolkit such as RIOT-ML is essential to expedite research combining artificial intelligence and IoT and to foster the full realization of edge computing's potential.},
  langid = {english},
  keywords = {AI,Benchmarks,CT: Tool,IoT,Low power,Machine learning,Microcontroller,MLOps,RT: Validation Research,Software update},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Huang et al. - 2024 - RIOT-ML toolkit for over-the-air secure updates and performance evaluation of TinyML models.docx;/Users/lukasgrodmeier/Zotero/storage/PT9HZMPZ/Huang et al. - 2024 - RIOT-ML toolkit for over-the-air secure updates and performance evaluation of TinyML models.pdf}
}

@article{immonenTinyMachineLearning2022,
  title = {Tiny {{Machine Learning}} for {{Resource-Constrained Microcontrollers}}},
  author = {Immonen, Riku and H{\"a}m{\"a}l{\"a}inen, Timo},
  year = {2022},
  journal = {Journal of Sensors},
  volume = {2022},
  number = {1},
  pages = {7437023},
  issn = {1687-7268},
  doi = {10.1155/2022/7437023},
  urldate = {2025-02-08},
  abstract = {We use 250 billion microcontrollers daily in electronic devices that are capable of running machine learning models inside them. Unfortunately, most of these microcontrollers are highly constrained in terms of computational resources, such as memory usage or clock speed. These are exactly the same resources that play a key role in teaching and running a machine learning model with a basic computer. However, in a microcontroller environment, constrained resources make a critical difference. Therefore, a new paradigm known as tiny machine learning had to be created to meet the constrained requirements of the embedded devices. In this review, we discuss the resource optimization challenges of tiny machine learning and different methods, such as quantization, pruning, and clustering, that can be used to overcome these resource difficulties. Furthermore, we summarize the present state of tiny machine learning frameworks, libraries, development environments, and tools. The benchmarking of tiny machine learning devices is another thing to be concerned about; these same constraints of the microcontrollers and diversity of hardware and software turn to benchmark challenges that must be resolved before it is possible to measure performance differences reliably between embedded devices. We also discuss emerging techniques and approaches to boost and expand the tiny machine learning process and improve data privacy and security. In the end, we form a conclusion about tiny machine learning and its future development.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/YNUKUFBY/Immonen und Hämäläinen - 2022 - Tiny Machine Learning for Resource-Constrained Microcontrollers.pdf;/Users/lukasgrodmeier/Zotero/storage/ZEYKHSW4/7437023.html}
}

@inproceedings{johnMLOpsFrameworkMaturity2021,
  title = {Towards {{MLOps}}: {{A Framework}} and {{Maturity Model}}},
  shorttitle = {Towards {{MLOps}}},
  booktitle = {2021 47th {{Euromicro Conference}} on {{Software Engineering}} and {{Advanced Applications}} ({{SEAA}})},
  author = {John, Meenu Mary and Olsson, Helena Holmstr{\"o}m and Bosch, Jan},
  year = {2021},
  month = sep,
  pages = {1--8},
  doi = {10.1109/SEAA53835.2021.00050},
  urldate = {2024-12-07},
  abstract = {The adoption of continuous software engineering practices such as DevOps (Development and Operations) in business operations has contributed to significantly shorter software development and deployment cycles. Recently, the term MLOps (Machine Learning Operations) has gained increasing interest as a practice that brings together data scientists and operations teams. However, the adoption of MLOps in practice is still in its infancy and there are few common guidelines on how to effectively integrate it into existing software development practices. In this paper, we conduct a systematic literature review and a grey literature review to derive a framework that identifies the activities involved in the adoption of MLOps and the stages in which companies evolve as they become more mature and advanced. We validate this framework in three case companies and show how they have managed to adopt and integrate MLOps in their large-scale software development companies. The contribution of this paper is threefold. First, we review contemporary literature to provide an overview of the state-of-the-art in MLOps. Based on this review, we derive an MLOps framework that details the activities involved in the continuous development of machine learning models. Second, we present a maturity model in which we outline the different stages that companies go through in evolving their MLOps practices. Third, we validate our framework in three embedded systems case companies and map the companies to the stages in the maturity model.},
  keywords = {Bibliographies,Companies,Embedded systems,Framework,GLR,Machine learning,Maturity Model,MLOps,SLR,Software,Software engineering,Systematics,Validation Study},
  file = {/Users/lukasgrodmeier/Zotero/storage/T37RKDXF/John et al. - 2021 - Towards MLOps A Framework and Maturity Model.pdf}
}

@article{jolliffePrincipalComponentAnalysis2016,
  title = {Principal Component Analysis: A Review and Recent Developments},
  shorttitle = {Principal Component Analysis},
  author = {Jolliffe, Ian T. and Cadima, Jorge},
  year = {2016},
  month = apr,
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {374},
  number = {2065},
  pages = {20150202},
  publisher = {Royal Society},
  doi = {10.1098/rsta.2015.0202},
  urldate = {2025-05-22},
  abstract = {Large datasets are increasingly common and are often difficult to interpret. Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance. Finding such new variables, the principal components, reduces to solving an eigenvalue/eigenvector problem, and the new variables are defined by the dataset at hand, not a priori, hence making PCA an adaptive data analysis technique. It is adaptive in another sense too, since variants of the technique have been developed that are tailored to various different data types and structures. This article will begin by introducing the basic ideas of PCA, discussing what it can and cannot do. It will then describe some variants of PCA and their application.},
  keywords = {dimension reduction,eigenvectors,multivariate analysis,palaeontology},
  file = {/Users/lukasgrodmeier/Zotero/storage/HSHB5H4L/Jolliffe und Cadima - 2016 - Principal component analysis a review and recent developments.pdf}
}

@article{karamitsosApplyingDevOpsPractices2020,
  title = {Applying {{DevOps Practices}} of {{Continuous Automation}} for {{Machine Learning}}},
  author = {Karamitsos, Ioannis and Albarhami, Saeed and Apostolopoulos, Charalampos},
  year = {2020},
  month = jul,
  journal = {Information},
  volume = {11},
  number = {7},
  pages = {363},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info11070363},
  urldate = {2024-12-07},
  abstract = {This paper proposes DevOps practices for machine learning application, integrating both the development and operation environment seamlessly. The machine learning processes of development and deployment during the experimentation phase may seem easy. However, if not carefully designed, deploying and using such models may lead to a complex, time-consuming approaches which may require significant and costly efforts for maintenance, improvement, and monitoring. This paper presents how to apply continuous integration (CI) and continuous delivery (CD) principles, practices, and tools so as to minimize waste, support rapid feedback loops, explore the hidden technical debt, improve value delivery and maintenance, and improve operational functions for real-world machine learning applications.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {CD,CI,CRISP-DM,DevOps,machine learning,pipeline,SEMMA,TDSP},
  file = {/Users/lukasgrodmeier/Zotero/storage/BQYRQQGW/Karamitsos et al. - 2020 - Applying DevOps Practices of Continuous Automation for Machine Learning.pdf}
}

@article{kitchenhamGuidelinesPerformingSystematic2007,
  title = {Guidelines for Performing {{Systematic Literature Reviews}} in {{Software Engineering}}},
  author = {Kitchenham, Barbara and Charters, Stuart},
  year = {2007},
  month = jan,
  volume = {2},
  abstract = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest.  Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.}
}

@article{kreuzbergerMachineLearningOperations2023,
  title = {Machine {{Learning Operations}} ({{MLOps}}): {{Overview}}, {{Definition}}, and {{Architecture}}},
  shorttitle = {Machine {{Learning Operations}} ({{MLOps}})},
  author = {Kreuzberger, Dominik and K{\"u}hl, Niklas and Hirschl, Sebastian},
  year = {2023},
  journal = {IEEE Access},
  volume = {11},
  pages = {31866--31879},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3262138},
  urldate = {2024-12-07},
  abstract = {The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.},
  keywords = {Automation,Bibliographies,CI/CD,Codes,Collaboration,DevOps,Interviews,machine learning,Machine learning,MLOps,operations,Training,workflow orchestration},
  file = {/Users/lukasgrodmeier/Zotero/storage/BJT2SNHX/Kreuzberger et al. - 2023 - Machine Learning Operations (MLOps) Overview, Definition, and Architecture.pdf}
}

@inproceedings{kwonLifeLearnerHardwareAwareMeta2023,
  title = {{{LifeLearner}}: {{Hardware-Aware Meta Continual Learning System}} for {{Embedded Computing Platforms}}},
  shorttitle = {{{LifeLearner}}},
  booktitle = {Proceedings of the 21st {{ACM Conference}} on {{Embedded Networked Sensor Systems}}},
  author = {Kwon, Young D. and Chauhan, Jagmohan and Jia, Hong and Venieris, Stylianos I. and Mascolo, Cecilia},
  year = {2023},
  month = nov,
  pages = {138--151},
  publisher = {ACM},
  address = {Istanbul Turkiye},
  doi = {10.1145/3625687.3625804},
  urldate = {2025-01-05},
  isbn = {979-8-4007-0414-7},
  langid = {english},
  keywords = {CT: Framework,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Zotero/storage/QA6HB2BQ/Kwon et al. - 2023 - LifeLearner Hardware-Aware Meta Continual Learning System for Embedded Computing Platforms.pdf}
}

@article{lakensEquivalenceTestsPractical2017,
  title = {Equivalence {{Tests}}: {{A Practical Primer}} for t {{Tests}}, {{Correlations}}, and {{Meta-Analyses}}},
  shorttitle = {Equivalence {{Tests}}},
  author = {Lakens, Dani{\"e}l},
  year = {2017},
  month = may,
  journal = {Social Psychological and Personality Science},
  volume = {8},
  number = {4},
  pages = {355--362},
  issn = {1948-5506},
  doi = {10.1177/1948550617697177},
  abstract = {Scientists should be able to provide support for the absence of a meaningful effect. Currently, researchers often incorrectly conclude an effect is absent based a nonsignificant result. A widely recommended approach within a frequentist framework is to test for equivalence. In equivalence tests, such as the two one-sided tests (TOST) procedure discussed in this article, an upper and lower equivalence bound is specified based on the smallest effect size of interest. The TOST procedure can be used to statistically reject the presence of effects large enough to be considered worthwhile. This practical primer with accompanying spreadsheet and R package enables psychologists to easily perform equivalence tests (and power analyses) by setting equivalence bounds based on standardized effect sizes and provides recommendations to prespecify equivalence bounds. Extending your statistical tool kit with equivalence tests is an easy way to improve your statistical and theoretical inferences.},
  langid = {english},
  pmcid = {PMC5502906},
  pmid = {28736600},
  keywords = {equivalence testing,null hypothesis significance testing,power analysis,research methods},
  file = {/Users/lukasgrodmeier/Zotero/storage/GFX5YHP3/Lakens - 2017 - Equivalence Tests A Practical Primer for t Tests, Correlations, and Meta-Analyses.pdf}
}

@inproceedings{lerouxTinyMLOpsOperationalChallenges2022a,
  title = {{{TinyMLOps}}: {{Operational Challenges}} for {{Widespread Edge AI Adoption}}},
  shorttitle = {{{TinyMLOps}}},
  booktitle = {2022 {{IEEE International Parallel}} and {{Distributed Processing Symposium Workshops}} ({{IPDPSW}})},
  author = {Leroux, Sam and Simoens, Pieter and Lootus, Meelis and Thakore, Kartik and Sharma, Akshay},
  year = {2022},
  month = may,
  pages = {1003--1010},
  doi = {10.1109/IPDPSW55747.2022.00160},
  urldate = {2024-12-13},
  abstract = {Deploying machine learning applications on edge devices can bring clear benefits such as improved reliability, latency and privacy but it also introduces its own set of challenges. Most works focus on the limited computational resources of edge platforms but this is not the only bottleneck standing in the way of widespread adoption. In this paper we list several other challenges that a Tiny ML practitioner might need to consider when operationalizing an application on edge devices. We focus on tasks such as monitoring and managing the application, common functionality for a MLOps platform, and show how they are complicated by the distributed nature of edge deployment. We also discuss issues that are unique to edge applications such as protecting a model's intellectual property and verifying its integrity.},
  keywords = {Conferences,Distributed processing,Edge AI,Intellectual property,Machine learning,MLOps,Privacy,Reliability,Task analysis,TinyML,TinyMLOps},
  file = {/Users/lukasgrodmeier/Zotero/storage/JN6BWTHG/Leroux et al. - 2022 - TinyMLOps Operational Challenges for Widespread Edge AI Adoption.pdf}
}

@inproceedings{leTinyMLOpsRealtimeUltralow2023a,
  title = {{{TinyMLOps}} for Real-Time Ultra-Low Power {{MCUs}} Applied to Frame-Based Event Classification},
  booktitle = {Proceedings of the 3rd {{Workshop}} on {{Machine Learning}} and {{Systems}}},
  author = {L{\^e}, Minh Tri and Arbel, Julyan},
  year = {2023},
  month = may,
  series = {{{EuroMLSys}} '23},
  pages = {148--153},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3578356.3592586},
  urldate = {2024-12-13},
  abstract = {TinyML applications such as speech recognition, motion detection, or anomaly detection are attracting many industries and researchers thanks to their innovative and cost-effective potential. Since tinyMLOps is at an even earlier stage than MLOps, the best practices and tools of tinyML are yet to be found to deliver seamless production-ready applications. TinyMLOps has common challenges with MLOps, but it differs from it because of its hard footprint constraints. In this work, we analyze the steps of successful tinyMLOps with a highlight on challenges and solutions in the case of real-time frame-based event classification on low-power devices. We also report a comparative result of our tinyMLOps solution against tf.lite and NNoM.},
  isbn = {979-8-4007-0084-2},
  keywords = {CT: Guideline,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Lê und Arbel - 2023 - TinyMLOps for real-time ultra-low power MCUs applied to frame-based event classification.docx;/Users/lukasgrodmeier/Zotero/storage/86ATM8ZU/Lê und Arbel - 2023 - TinyMLOps for real-time ultra-low power MCUs applied to frame-based event classification.pdf}
}

@inproceedings{linMCUNetTinyDeep2020a,
  title = {{{MCUNet}}: {{Tiny Deep Learning}} on {{IoT Devices}}},
  shorttitle = {{{MCUNet}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lin, Ji and Chen, Wei-Ming and Lin, Yujun and {cohn}, john and Gan, Chuang and Han, Song},
  year = {2020},
  volume = {33},
  pages = {11711--11722},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-02-08},
  abstract = {Machine learning on tiny IoT devices based on microcontroller units (MCU) is appealing but challenging: the memory of microcontrollers is 2-3 orders of magnitude smaller even than mobile phones. We propose MCUNet, a framework that jointly designs the efficient neural architecture (TinyNAS) and the lightweight inference engine (TinyEngine), enabling ImageNet-scale inference on microcontrollers. TinyNAS adopts a two-stage neural architecture search approach that first optimizes the search space to fit the resource constraints, then specializes the network architecture in the optimized search space. TinyNAS can automatically handle diverse constraints (i.e. device, latency, energy, memory) under low search costs. TinyNAS is co-designed with TinyEngine, a memory-efficient inference library to expand the search space and fit a larger model. TinyEngine adapts the memory scheduling according to the overall network topology rather than layer-wise optimization, reducing the memory usage by 3.4{\texttimes}, and accelerating the inference by 1.7-3.3{\texttimes} compared to TF-Lite Micro [3] and CMSIS-NN [28]. MCUNet is the first to achieves {$>$}70\% ImageNet top1 accuracy on an off-the-shelf commercial microcontroller, using 3.5{\texttimes} less SRAM and 5.7{\texttimes} less Flash compared to quantized MobileNetV2 and ResNet-18. On visual\&audio wake words tasks, MCUNet achieves state-of-the-art accuracy and runs 2.4-3.4{\texttimes} faster than Mo- bileNetV2 and ProxylessNAS-based solutions with 3.7-4.1{\texttimes} smaller peak SRAM. Our study suggests that the era of always-on tiny machine learning on IoT devices has arrived.},
  file = {/Users/lukasgrodmeier/Zotero/storage/PLY88V9R/Lin et al. - 2020 - MCUNet Tiny Deep Learning on IoT Devices.pdf}
}

@article{linTinyMachineLearning2024,
  title = {Tiny Machine Learning Empowers Climbing Inspection Robots for Real-Time Multiobject Bolt-Defect Detection},
  author = {Lin, Tzu-Hsuan and Chang, Chien-Ta and Putranto, Alan},
  year = {2024},
  month = jul,
  journal = {Engineering Applications of Artificial Intelligence},
  volume = {133},
  pages = {108618},
  issn = {09521976},
  doi = {10.1016/j.engappai.2024.108618},
  urldate = {2025-01-04},
  abstract = {Ensuring the structural integrity of steel construction is critical, necessitating effective methods for detecting bolt defects. Traditional inspection methods are reliable but require significant labor and struggle with the accessibility of complex structures. This research introduces a real-time bolt-defect detection system that integrates tiny machine learning (TinyML) with a magnetic climbing robot to enhance inspection efficiency and scope. The system employs the faster objects, more objects (FOMO) algorithm optimized for edge computing on microcontrollers. This approach enables accurate bolt identification, including normal, loose, and missing bolts. The average system accuracy is 82\%, with precision and recall values from 0.57 to 0.89 and 0.67 to 0.87, respectively. The system demonstrates balanced detection, evidenced by an F1 score improvement of up to 62\%. The FOMO model displays compelling performance on defect detection tasks, achieving an F1 score of approximately 75\%, outperforming the MobileNetV2 Single Shot Multibox Detector with Feature Pyramid Networks Lite and You Only Look Once version 5 small. The efficiency of the FOMO model is highlighted by its low hardware requirements at less than 0.1 MB of flash memory and 893.8 KB of random access memory for the 32-bit floatingpoint data format and is reduced for the 8-bit integer data format, with inference times of 142 ms and 86 ms, respectively. These findings contrast with the higher resource demands and slower inference time of the compared models, indicating the suitability of the FOMO model for low-capacity microcontrollers and its feasibility for real-time applications. The performance analysis across scenarios confirms the high precision (average 0.77) and recall (average 0.76), validating the robustness of the model in diverse environmental conditions. The system offers an advancement over traditional bolt-defect detection methods in accuracy and efficiency by leveraging TinyML and a magnetic climbing robot, setting new benchmarks for real-time inspection technology. The quantitative results underscore the performance of the system, presenting a scalable, costeffective solution for improving the safety and durability of steel structures.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/NGQ7QZKP/Lin et al. - 2024 - Tiny machine learning empowers climbing inspection robots for real-time multiobject bolt-defect dete.pdf}
}

@inproceedings{lootusVMContainerizedApproach2022,
  title = {A {{VM}}/{{Containerized Approach}} for {{Scaling TinyML Applications}}},
  author = {Lootus, Meelis and Thakore, Kartik and Leroux, Sam and Trooskens, Geert and Sharma, Akshay and Ly, Holly},
  year = {2022},
  month = feb,
  eprint = {2202.05057},
  primaryclass = {cs},
  publisher = {Research Symposium},
  doi = {10.48550/arXiv.2202.05057},
  urldate = {2024-12-14},
  abstract = {Although deep neural networks are typically computationally expensive to use, technological advances in both the design of hardware platforms and of neural network architectures, have made it possible to use powerful models on edge devices. To enable widespread adoption of edge based machine learning, we introduce a set of open-source tools that make it easy to deploy, update and monitor machine learning models on a wide variety of edge devices. Our tools bring the concept of containerization to the TinyML world. We propose to package ML and application logic as containers called Runes to deploy onto edge devices. The containerization allows us to target a fragmented Internet-of-Things (IoT) ecosystem by providing a common platform for Runes to run across devices.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Software Engineering,CT: Framework,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Lootus et al. - 2022 - A VMContainerized Approach for Scaling TinyML Applications.docx;/Users/lukasgrodmeier/Zotero/storage/ZII2UUMK/Lootus et al. - 2022 - A VMContainerized Approach for Scaling TinyML Applications.pdf}
}

@article{mannTestWhetherOne1947,
  title = {On a {{Test}} of {{Whether}} One of {{Two Random Variables}} Is {{Stochastically Larger}} than the {{Other}}},
  author = {Mann, H. B. and Whitney, D. R.},
  year = {1947},
  month = mar,
  journal = {The Annals of Mathematical Statistics},
  volume = {18},
  number = {1},
  pages = {50--60},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177730491},
  urldate = {2025-05-27},
  abstract = {Let \$x\$ and \$y\$ be two random variables with continuous cumulative distribution functions \$f\$ and \$g\$. A statistic \$U\$ depending on the relative ranks of the \$x\$'s and \$y\$'s is proposed for testing the hypothesis \$f = g\$. Wilcoxon proposed an equivalent test in the Biometrics Bulletin, December, 1945, but gave only a few points of the distribution of his statistic. Under the hypothesis \$f = g\$ the probability of obtaining a given \$U\$ in a sample of \$n x's\$ and \$m y's\$ is the solution of a certain recurrence relation involving \$n\$ and \$m\$. Using this recurrence relation tables have been computed giving the probability of \$U\$ for samples up to \$n = m = 8\$. At this point the distribution is almost normal. From the recurrence relation explicit expressions for the mean, variance, and fourth moment are obtained. The 2rth moment is shown to have a certain form which enabled us to prove that the limit distribution is normal if \$m, n\$ go to infinity in any arbitrary manner. The test is shown to be consistent with respect to the class of alternatives \$f(x) {$>$} g(x)\$ for every \$x\$.},
  file = {/Users/lukasgrodmeier/Zotero/storage/DVR7TIJ4/Mann und Whitney - 1947 - On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other.pdf}
}

@article{minSensiXBringingMLOps2023,
  title = {{{SensiX}}++: {{Bringing MLOps}} and {{Multi-tenant Model Serving}} to {{Sensory Edge Devices}}},
  shorttitle = {{{SensiX}}++},
  author = {Min, Chulhong and Mathur, Akhil and Acer, Utku G{\"u}nay and Montanari, Alessandro and Kawsar, Fahim},
  year = {2023},
  month = nov,
  journal = {ACM Trans. Embed. Comput. Syst.},
  volume = {22},
  number = {6},
  pages = {98:1--98:27},
  issn = {1539-9087},
  doi = {10.1145/3617507},
  urldate = {2024-12-07},
  abstract = {We present SensiX++, a multi-tenant runtime for adaptive model execution with integrated MLOps on edge devices, e.g., a camera, a microphone, or IoT sensors. SensiX++ operates on two fundamental principles: highly modular componentisation to externalise data operations with clear abstractions and document-centric manifestation for system-wide orchestration. First, a data coordinator manages the lifecycle of sensors and serves models with correct data through automated transformations. Next, a resource-aware model server executes multiple models in isolation through model abstraction, pipeline automation, and feature sharing. An adaptive scheduler then orchestrates the best-effort executions of multiple models across heterogeneous accelerators, balancing latency and throughput. Finally, microservices with REST APIs serve synthesised model predictions, system statistics, and continuous deployment. Collectively, these components enable SensiX++ to serve multiple models efficiently with fine-grained control on edge devices while minimising data operation redundancy, managing data and device heterogeneity, and reducing resource contention. We benchmark SensiX++ with 10 different vision and acoustics models across various multi-tenant configurations on different edge accelerators (Jetson AGX and Coral TPU) designed for sensory devices. We report on the overall throughput and quantified benefits of various automation components of SensiX++ and demonstrate its efficacy in significantly reducing operational complexity and lowering the effort to deploy, upgrade, reconfigure, and serve embedded models on edge devices.},
  keywords = {CT: Framework,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Min et al. - 2023 - SensiX++ Bringing MLOps and Multi-tenant Model Serving to Sensory Edge Devices.docx;/Users/lukasgrodmeier/Zotero/storage/87PU8UFF/Min et al. - 2023 - SensiX++ Bringing MLOps and Multi-tenant Model Serving to Sensory Edge Devices.pdf}
}

@article{moskalenkoResilienceawareMLOpsResourceconstrained2023,
  title = {Resilience-Aware {{MLOps}} for Resource-Constrained {{AI-}} System},
  author = {Moskalenko, Viacheslav and Moskalenko, Alona and Kudryavtsev, Anton},
  year = {2023},
  abstract = {Artificial intelligence systems are increasingly used in security-critical applications with limited computing resources, which makes them vulnerable to such disturbances as adversarial attack noise, out-of-distribution data, and fault injections. To absorb disturbances and adapt the AI system during its life cycle, it is necessary to expand the Machine learning operations structure with stages related to the implementation of resilience mechanisms. In this case, increasing resilience in one form or another is associated with the introduction of redundancy in the form of additional resources to absorb disturbances and quickly recover performance. It is proposed to provide Affordable Resilience for resource-constrained AI systems by implementing a resilience optimization stage and adding add-ons with a small number of parameters that will allow for uncertainty calibration and rapid adaptation to labeled and unlabeled data. This approach is also intended to separate the work related to the development and deployment of the basic AI model that solves the applied problem and the work related to ensuring resilience in the Machine learning operations structure. The experiments were conducted on CIFAR-10 and CIFAR-100 datasets using the MobileViT network, which is a modern network architecture for visual image analysis in conditions of limited computing resources. We have experimentally confirmed the increase in the resilience of an AI system at different stages of its life cycle by implementing the stages of resilience optimization, uncertainty calibration, and Test-Time Adaptation. Post-hoc resilience optimization improved robustness to fault injection by 5\% and robustness to adversarial attack by 7\%. Moreover, tuning with 10\% of the test data allowed for an additional 6\% increase in robustness to fault injection and 7.1\% increase in robustness to adversarial attack on the new data. Also, the use of post-hoc resilience optimization increased the integral indicator of resilience to task changes by 10.5\%. Post-hoc uncertainty calibration makes it possible to further increase the robustness of fault injection models by an average of 4.4\% and the robustness to adversarial attacks by an average of 1.3\%. Test-Time Adaptation increases robustness to Fault Injection by 6.9\% and robustness to Adversarial Attack by 4.72\%.},
  langid = {english},
  keywords = {CT: Framework,RT: Validation Research},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Moskalenko et al. - Resilience-aware MLOps for resource-constrained AI- system.docx;/Users/lukasgrodmeier/Zotero/storage/QCK8DN3Y/Moskalenko et al. - Resilience-aware MLOps for resource-constrained AI- system.pdf}
}

@article{ookoApplicationTinyMachine2024,
  title = {Application of {{Tiny Machine Learning}} in {{Predicative Maintenance}} in {{Industries}}},
  author = {Ooko, Samson O. and Karume, Simon M.},
  year = {2024},
  month = aug,
  journal = {Journal of Computing Theories and Applications},
  volume = {2},
  number = {1},
  pages = {131--150},
  issn = {3024-9104},
  doi = {10.62411/jcta.10929},
  urldate = {2024-12-07},
  abstract = {The continued advancements in Internet of Things (IoT) and Machine Learning (ML) technologies have led to their adoption in various domains including in industries for predictive maintenance among other applications. Given the resource constraints of IoT devices, they cannot process the resource-intensive ML algorithms hence data collected by the devices are first sent to the cloud where the algorithms are hosted for processing and inference with the results being sent back to the devices for action and/or notifications. The need to transmit data to the cloud for processing leads to increased costs, energy consumption, and high latencies affecting the implementation of the solution. Interestingly with Tiny Machine Learning (TinyML), it is possible to develop algorithms enabling edge inference on resource-constrained devices. From existing review papers, the researchers were not able to find, a comprehensive review with a focus on this area showing the need for a targeted review that can shed light on how TinyML can be tailored for predictive maintenance tasks in industries. This study therefore presents a systematic literature review of the application of TinyML in predictive maintenance in industrial settings. TinyML overview and its benefits are presented, a TinyML process flow is proposed and various use cases and their classifications have been presented. Through this exploration, the study shows the critical need for TinyML-driven solutions in predictive maintenance, identifies the existing challenges, and proposes a roadmap for future research.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/UB3KXA8T/Ooko und Karume - 2024 - Application of Tiny Machine Learning in Predicative Maintenance in Industries.pdf}
}

@article{pageContinuousInspectionSchemes1954,
  title = {Continuous {{Inspection Schemes}}},
  author = {Page, E. S.},
  year = {1954},
  journal = {Biometrika},
  volume = {41},
  number = {1/2},
  eprint = {2333009},
  eprinttype = {jstor},
  pages = {100--115},
  publisher = {[Oxford University Press, Biometrika Trust]},
  issn = {0006-3444},
  doi = {10.2307/2333009},
  urldate = {2025-05-22}
}

@article{pavanTyBoxAutomaticDesign2024,
  title = {{{TyBox}}: {{An Automatic Design}} and {{Code Generation Toolbox}} for {{TinyML Incremental On-Device Learning}}},
  shorttitle = {{{TyBox}}},
  author = {Pavan, Massimo and Ostrovan, Eugeniu and Caltabiano, Armando and Roveri, Manuel},
  year = {2024},
  month = may,
  journal = {ACM Transactions on Embedded Computing Systems},
  volume = {23},
  number = {3},
  pages = {1--27},
  issn = {1539-9087, 1558-3465},
  doi = {10.1145/3604566},
  urldate = {2024-12-21},
  abstract = {Incremental on-device learning is one of the most relevant and interesting challenges in the field of Tiny Machine Learning (TinyML). Indeed, differently from traditional TinyML solutions where the training is typically carried out on the Cloud and inference only occurs on the tiny devices (e.g., embedded systems or Internet-of-Things units), incremental on-device TinyML allows both the inference and the training of TinyML models directly on tiny devices.             This ability paves the way for TinyML-enabled intelligent devices that can learn directly on the field and adapt to evolving environments, different working conditions, or specific users. The literature in this field is quite limited with very few solutions focusing only on the incremental fine-tuning of machine learning models, whereas a general solution encompassing algorithms and code generation for incremental on-device TinyML is still perceived as missing.                            The aim of this article is to introduce, to the best of our knowledge for the first time in the literature, a toolbox called               TyBox               for the automatic design and code generation of incremental on-device TinyML classification models. In more detail, starting from a ``static'' TinyML model, TyBox is able to (i) automatically design the ``incremental'' on-device version of the TinyML model that has been suitably designed to take into account the technological constraint on the RAM memory of the target tiny device, and (ii) autonomously provide the C++ codes and libraries to support the inference and learning of the incremental on-device TinyML model directly on the tiny devices.                          TyBox has been extensively compared with a state-of-the-art incremental learning solution for TinyML and tested on an off-the-shelf tiny device (i.e., the Arduino Nano 33 BLE) in three relevant TinyML application tasks and scenarios: binary image classification, multi-class image classification, and ultra-wide-band human activity recognition. In addition, TyBox is released to the scientific community as a public repository.},
  langid = {english},
  keywords = {CT: Tool,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Pavan et al. - 2024 - TyBox An Automatic Design and Code Generation Toolbox for TinyML Incremental On-Device Learning.docx;/Users/lukasgrodmeier/Zotero/storage/HIV8D4GV/Pavan et al. - 2024 - TyBox An Automatic Design and Code Generation Toolbox for TinyML Incremental On-Device Learning.pdf}
}

@inproceedings{peffersDesignScienceResearch2012,
  title = {Design {{Science Research Evaluation}}},
  booktitle = {Design {{Science Research}} in {{Information Systems}}. {{Advances}} in {{Theory}} and {{Practice}}},
  author = {Peffers, Ken and Rothenberger, Marcus and Tuunanen, Tuure and Vaezi, Reza},
  editor = {Peffers, Ken and Rothenberger, Marcus and Kuechler, Bill},
  year = {2012},
  pages = {398--410},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-29863-9_29},
  abstract = {The consensus view is that the rigorous evaluation of design science (DS) artifacts is essential. There are many types of DS artifacts and many forms of evaluation; what is missing is guidance for how to perform the evaluation, more specifically, what evaluation methods to use with specific DS research outputs. Here we find and review 148 DS research articles published in a selected set of information systems (IS), computer science (CS) and engineering journals. We analyze the articles to develop taxonomies of DS artifact types and artifact evaluation methods; we apply these taxonomies to determine which evaluation methods are associated in the literature with particular artifacts. We show that there are several popular ``artifact - evaluation method'' combinations in the literature. The results inform DS researchers of usual and customary combinations of research artifacts and evaluation methods, potentially providing them with rationale and justification for an evaluation method selection.},
  isbn = {978-3-642-29863-9},
  langid = {english},
  keywords = {artifacts,Design Science,evaluation}
}

@inproceedings{peltonenLinkEdgeOpensourcedMLOps2023,
  title = {{{LinkEdge}}: {{Open-sourced MLOps Integration}} with {{IoT Edge}}},
  shorttitle = {{{LinkEdge}}},
  booktitle = {Proceedings of the 3rd {{Eclipse Security}}, {{AI}}, {{Architecture}} and {{Modelling Conference}} on {{Cloud}} to {{Edge Continuum}}},
  author = {Peltonen, Ella and Dias, Savidu},
  year = {2023},
  month = oct,
  series = {{{eSAAM}} '23},
  pages = {67--76},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3624486.3624496},
  urldate = {2024-12-14},
  abstract = {MLOps, or Machine Learning Operations, play a significant role in streamlining production deployment, monitoring, and management of machine learning models. Integrating MLOps with edge devices poses unique challenges that require customised deployment strategies and efficient model optimisation techniques. This paper introduces LinkEdge, a set of tools that enable the integration of MLOps practices with edge devices. LinkEdge consists of two sets of tools: one for setting up infrastructure within edge devices to be able to receive, monitor, and run inference on ML models and another for MLOps pipelines to package models to be compatible with the inference and monitoring components of the respective edge devices. The LinkEdge platform is evaluated by obtaining a public dataset for predicting the breakdown of Air Pressure Systems in trucks. Additionally, the platform is compared against a commercial tool that serves similar purposes. The overall performance of LinkEdge matches that of already existing tools and services while allowing end users setting up Edge-MLOps infrastructure the complete freedom to set up their system without entirely relying on third-party licensed software.},
  isbn = {979-8-4007-0835-0},
  keywords = {CT: Tool,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Peltonen und Dias - 2023 - LinkEdge Open-sourced MLOps Integration with IoT Edge.docx;/Users/lukasgrodmeier/Zotero/storage/WMSX96AC/Peltonen und Dias - 2023 - LinkEdge Open-sourced MLOps Integration with IoT Edge.pdf}
}

@article{petersenGuidelinesConductingSystematic2015,
  title = {Guidelines for Conducting Systematic Mapping Studies in Software Engineering: {{An}} Update},
  shorttitle = {Guidelines for Conducting Systematic Mapping Studies in Software Engineering},
  author = {Petersen, Kai and Vakkalanka, Sairam and Kuzniarz, Ludwik},
  year = {2015},
  month = aug,
  journal = {Information and Software Technology},
  volume = {64},
  pages = {1--18},
  issn = {0950-5849},
  doi = {10.1016/j.infsof.2015.03.007},
  urldate = {2025-01-25},
  abstract = {Context Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines. Objective To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly. Method We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment). Results In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given. Conclusion The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.},
  keywords = {Guidelines,Software engineering,Systematic mapping studies},
  file = {/Users/lukasgrodmeier/Zotero/storage/PWDE6BDR/S0950584915000646.html}
}

@inproceedings{rajEdgeMLOpsAutomation2021,
  title = {Edge {{MLOps}}: {{An Automation Framework}} for {{AIoT Applications}}},
  shorttitle = {Edge {{MLOps}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Cloud Engineering}} ({{IC2E}})},
  author = {Raj, Emmanuel and Buffoni, David and Westerlund, Magnus and Ahola, Kimmo},
  year = {2021},
  month = oct,
  pages = {191--200},
  doi = {10.1109/IC2E52221.2021.00034},
  urldate = {2024-12-07},
  abstract = {Artificial Intelligence of Things (AIoT) is the combination of artificial intelligence (AI) technologies with the Internet of Things (IoT) infrastructure to achieve more efficient IoT operations and decision making. Edge computing is emerging to enable AIoT applications. In this paper, we develop an Edge MLOps framework for automating Machine Learning at the edge, enabling continuous model training, deployment, delivery and monitoring. To achieve this, we synergize cloud and edge environments. We experimentally validate our framework on a forecasting air quality situation. During validation, the framework showed stability and automatically retrained, integrated, and deployed models for specific environments when their performance deteriorated under a certain threshold.},
  keywords = {5G Networks,AI,Atmospheric modeling,Automation,Cloud computing,Collaborative work,Computational modeling,CT: Framework,Digital Transformation,Edge Computing,IoT,Machine Learning,MLOps,Pipelines,RT: Solution Paper,Training},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Raj et al. - 2021 - Edge MLOps An Automation Framework for AIoT Applications.docx;/Users/lukasgrodmeier/Zotero/storage/HBDS8AG7/Raj et al. - 2021 - Edge MLOps An Automation Framework for AIoT Applications.pdf}
}

@article{rayReviewTinyMLStateoftheart2022,
  title = {A Review on {{TinyML}}: {{State-of-the-art}} and Prospects},
  shorttitle = {A Review on {{TinyML}}},
  author = {Ray, Partha Pratim},
  year = {2022},
  month = apr,
  journal = {Journal of King Saud University - Computer and Information Sciences},
  volume = {34},
  number = {4},
  pages = {1595--1623},
  issn = {1319-1578},
  doi = {10.1016/j.jksuci.2021.11.019},
  urldate = {2024-12-07},
  abstract = {Machine learning has become an indispensable part of the existing technological domain. Edge computing and Internet of Things (IoT) together presents a new opportunity to imply machine learning techniques at the resource constrained embedded devices at the edge of the network. Conventional machine learning requires enormous amount of power to predict a scenario. Embedded machine learning -- TinyML paradigm aims to shift such plethora from traditional high-end systems to low-end clients. Several challenges are paved while doing such transition such as, maintaining the accuracy of learning models, provide train-to-deploy facility in resource frugal tiny edge devices, optimizing processing capacity, and improving reliability. In this paper, we present an intuitive review about such possibilities for TinyML. We firstly, present background of TinyML. Secondly, we list the tool sets for supporting TinyML. Thirdly, we present key enablers for improvement of TinyML systems. Fourthly, we present state-of-the-art about frameworks for TinyML. Finally, we identify key challenges and prescribe a future roadmap for mitigating several research issues of TinyML.},
  keywords = {Edge intelligence,Embedded AI,Energy efficient AI,IoT,Resource constrained intelligence,TinyML},
  file = {/Users/lukasgrodmeier/Zotero/storage/6PBB7GDH/Ray - 2022 - A review on TinyML State-of-the-art and prospects.pdf}
}

@inproceedings{recupitoMultivocalLiteratureReview2022a,
  title = {A {{Multivocal Literature Review}} of {{MLOps Tools}} and {{Features}}},
  booktitle = {2022 48th {{Euromicro Conference}} on {{Software Engineering}} and {{Advanced Applications}} ({{SEAA}})},
  author = {Recupito, Gilberto and Pecorelli, Fabiano and Catolino, Gemma and Moreschini, Sergio and Nucci, Dario Di and Palomba, Fabio and Tamburri, Damian A.},
  year = {2022},
  month = aug,
  pages = {84--91},
  doi = {10.1109/SEAA56994.2022.00021},
  urldate = {2025-02-08},
  abstract = {DevOps has become increasingly widespread, with companies employing its methods in different fields. In this context, MLOps automates Machine Learning pipelines by applying DevOps practices. Considering the high number of tools available and the high interest of the practitioners to be supported by tools to automate the steps of Machine Learning pipelines, little is known concerning MLOps tools and their functionalities. To this aim, we conducted a Multivocal Literature Review (MLR) to (i) extract tools that allow for and support the creation of MLOps pipelines and (ii) analyze their main characteristics and features to provide a comprehensive overview of their value. Overall, we investigate the functionalities of 13 MLOps Tools. Our results show that most MLOps Tools support the same features but apply different approaches that can bring different advantages, depending on user requirements.},
  keywords = {Bibliographies,Companies,DevOps,Feature extraction,Machine learning,Machine Learning,MLOps,Multivocal Literature Review,Pipelines,Software engineering},
  file = {/Users/lukasgrodmeier/Zotero/storage/EZDKF9VY/10011505.html}
}

@article{renOndeviceOnlineLearning2024,
  title = {On-Device {{Online Learning}} and {{Semantic Management}} of {{TinyML Systems}}},
  author = {Ren, Haoyu and Anicic, Darko and Li, Xue and Runkler, Thomas},
  year = {2024},
  month = jun,
  journal = {ACM Trans. Embed. Comput. Syst.},
  volume = {23},
  number = {4},
  pages = {55:1--55:32},
  issn = {1539-9087},
  doi = {10.1145/3665278},
  urldate = {2024-12-13},
  abstract = {Recent advances in Tiny Machine Learning (TinyML) empower low-footprint embedded devices for real-time on-device Machine Learning (ML). While many acknowledge the potential benefits of TinyML, its practical implementation presents unique challenges. This study aims to bridge the gap between prototyping single TinyML models and developing reliable TinyML systems in production: (1)\&nbsp;Embedded devices operate in dynamically changing conditions. Existing TinyML solutions primarily focus on inference, with models trained offline on powerful machines and deployed as static objects. However, static models may underperform in the real world due to evolving input data distributions. We propose online learning to enable training on constrained devices, adapting local models toward the latest field conditions. (2)\&nbsp;Nevertheless, current on-device learning methods struggle with heterogeneous deployment conditions and the scarcity of labeled data when applied across numerous devices. We introduce federated meta-learning incorporating online learning to enhance model generalization, facilitating rapid learning. This approach ensures optimal performance among distributed devices by knowledge sharing. (3)\&nbsp;Moreover, TinyML's pivotal advantage is widespread adoption. Embedded devices and TinyML models prioritize extreme efficiency, leading to diverse characteristics ranging from memory and sensors to model architectures. Given their diversity and non-standardized representations, managing these resources becomes challenging as TinyML systems scale up. We present semantic management for the joint management of models and devices at scale. We demonstrate our methods through a basic regression example and then assess them in three real-world TinyML applications: handwritten character image classification, keyword audio classification, and smart building presence detection. The results confirm the effectiveness of our approaches from various perspectives, such as accuracy improvement, resource savings, and engineering effort reduction.},
  keywords = {CT: Framework,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Ren et al. - 2024 - On-device Online Learning and Semantic Management of TinyML Systems.docx;/Users/lukasgrodmeier/Zotero/storage/X3QPQTRA/Ren et al. - 2024 - On-device Online Learning and Semantic Management of TinyML Systems.pdf}
}

@article{schuirmannComparisonTwoOneSided1987,
  title = {A Comparison of the {{Two One-Sided Tests Procedure}} and the {{Power Approach}} for Assessing the Equivalence of Average Bioavailability},
  author = {Schuirmann, Donald J.},
  year = {1987},
  month = dec,
  journal = {Journal of Pharmacokinetics and Biopharmaceutics},
  volume = {15},
  number = {6},
  pages = {657--680},
  issn = {0090-466X},
  doi = {10.1007/BF01068419},
  urldate = {2025-05-26},
  abstract = {The statistical test of the hypothesis of no difference between the average bioavailabilities of two drug formulations, usually supplemented by an assessment of what the power of the statistical test would have been if the true averages had been inequivalent, continues to be used in the statistical analysis of bioavailability/bioequivalence studies. In the present article, this Power Approach (which in practice usually consists of testing the hypothesis of no difference at level 0.05 and requiring an estimated power of 0.80) is compared to another statistical approach, the Two One-Sided Tests Procedure, which leads to the same conclusion as the approach proposed by Westlake (2) based on the usual (shortest) 1--2{$\alpha$} confidence interval for the true average difference. It is found that for the specific choice of {$\alpha$}=0.05 as the nominal level of the one-sided tests, the two one-sided tests procedure has uniformly superior properties to the power approach in most cases. The only cases where the power approach has superior properties when the true averages are equivalent correspond to cases where the chance of concluding equivalence with the power approach when the true averages are notequivalent exceeds 0.05. With appropriate choice of the nominal level of significance of the one-sided tests, the two one-sided tests procedure always has uniformly superior properties to the power approach. The two one-sided tests procedure is compared to the procedure proposed by Hauck and Anderson (1).},
  langid = {english},
  keywords = {Assessment and Testing,bioavailability,bioequivalence,Biostatistics,hypothesis testing,interval hypotheses,Performance Assessment,Power law,Statistical Theory and Methods,Statistics},
  file = {/Users/lukasgrodmeier/Zotero/storage/T3NS7UM7/Schuirmann - 1987 - A comparison of the Two One-Sided Tests Procedure and the Power Approach for assessing the equivalen.pdf}
}

@article{shapiroAnalysisVarianceTest,
  title = {An {{Analysis}} of {{Variance Test}} for {{Normality}} ({{Complete Samples}})},
  author = {Shapiro, S S and Wilk, M B},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/FA7CCDBG/Shapiro und Wilk - An Analysis of Variance Test for Normality (Complete Samples).pdf}
}

@inproceedings{shawWritingGoodSoftware2003,
  title = {Writing Good Software Engineering Research Papers},
  booktitle = {25th {{International Conference}} on {{Software Engineering}}, 2003. {{Proceedings}}.},
  author = {Shaw, M.},
  year = {2003},
  pages = {726--736},
  publisher = {IEEE},
  address = {Portland, OR, USA},
  doi = {10.1109/ICSE.2003.1201262},
  urldate = {2024-12-19},
  abstract = {Software engineering researchers solve problems of several different kinds. To do so, they produce several different kinds of results, and they should develop appropriate evidence to validate these results. They often report their research in conference papers. I analyzed the abstracts of research papers submitted to ICSE 2002 in order to identify the types of research reported in the submitted and accepted papers, and I observed the program committee discussions about which papers to accept. This report presents the research paradigms of the papers, common concerns of the program committee, and statistics on success rates. This information should help researchers design better research projects and write papers that present their results to best advantage.},
  isbn = {978-0-7695-1877-0},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/X6X6ZZ6Y/Shaw - 2003 - Writing good software engineering research papers.pdf}
}

@inproceedings{sudharsanEdge2TrainFrameworkTrain2020,
  title = {{{Edge2Train}}: A Framework to Train Machine Learning Models ({{SVMs}}) on Resource-Constrained {{IoT}} Edge Devices},
  shorttitle = {{{Edge2Train}}},
  booktitle = {Proceedings of the 10th {{International Conference}} on the {{Internet}} of {{Things}}},
  author = {Sudharsan, Bharath and Breslin, John G. and Ali, Muhammad Intizar},
  year = {2020},
  month = oct,
  pages = {1--8},
  publisher = {ACM},
  address = {Malm{\"o} Sweden},
  doi = {10.1145/3410992.3411014},
  urldate = {2024-12-16},
  isbn = {978-1-4503-8758-3},
  langid = {english},
  keywords = {CT: Framework,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Sudharsan et al. - 2020 - Edge2Train a framework to train machine learning models (SVMs) on resource-constrained IoT edge dev.docx;/Users/lukasgrodmeier/Zotero/storage/ELRZYLX5/Sudharsan et al. - 2020 - Edge2Train a framework to train machine learning models (SVMs) on resource-constrained IoT edge dev.pdf}
}

@article{sudharsanOTATinyMLAirDeployment2022,
  title = {{{OTA-TinyML}}: {{Over}} the {{Air Deployment}} of {{TinyML Models}} and {{Execution}} on {{IoT Devices}}},
  shorttitle = {{{OTA-TinyML}}},
  author = {Sudharsan, Bharath and Breslin, John G. and Tahir, Mehreen and Intizar Ali, Muhammad and Rana, Omer and Dustdar, Schahram and Ranjan, Rajiv},
  year = {2022},
  month = may,
  journal = {IEEE Internet Computing},
  volume = {26},
  number = {3},
  pages = {69--78},
  issn = {1941-0131},
  doi = {10.1109/MIC.2021.3133552},
  urldate = {2024-12-16},
  abstract = {This article presents a novel over-the-air (OTA) technique to remotely deploy tiny ML models over Internet of Things (IoT) devices and perform tasks, such as machine learning (ML) model updates, firmware reflashing, reconfiguration, or repurposing. We discuss relevant challenges for OTA ML deployment over IoT both at the scientific and engineering level. We propose OTA-TinyML to enable resource-constrained IoT devices to perform end-to-end fetching, storage, and execution of many TinyML models. OTA-TinyML loads the C source file of ML models from a web server into the embedded IoT devices via HTTPS. OTA-TinyML is tested by performing remote fetching of six types of ML models, storing them on four types of memory units, then loading and executing on seven popular MCU boards.},
  keywords = {Atmospheric modeling,CT: Tool,Internet of Things,Machine learning,Performance evaluation,RT: Solution Paper,Task analysis,Visualization,Web servers},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Sudharsan et al. - 2022 - OTA-TinyML Over the Air Deployment of TinyML Models and Execution on IoT Devices.docx;/Users/lukasgrodmeier/Zotero/storage/VU9MP7BH/Sudharsan et al. - 2022 - OTA-TinyML Over the Air Deployment of TinyML Models and Execution on IoT Devices.pdf}
}

@inproceedings{sudharsanTrainIncrementalML2021,
  title = {Train++: {{An Incremental ML Model Training Algorithm}} to {{Create Self-Learning IoT Devices}}},
  shorttitle = {Train++},
  booktitle = {2021 {{IEEE SmartWorld}}, {{Ubiquitous Intelligence}} \& {{Computing}}, {{Advanced}} \& {{Trusted Computing}}, {{Scalable Computing}} \& {{Communications}}, {{Internet}} of {{People}} and {{Smart City Innovation}} ({{SmartWorld}}/{{SCALCOM}}/{{UIC}}/{{ATC}}/{{IOP}}/{{SCI}})},
  author = {Sudharsan, Bharath and Yadav, Piyush and Breslin, John G. and Intizar Ali, Muhammad},
  year = {2021},
  month = oct,
  pages = {97--106},
  doi = {10.1109/SWC50871.2021.00023},
  urldate = {2024-12-16},
  abstract = {The majority of Internet of Things (IoT) devices are tiny embedded systems with a micro-controller unit (MCU) as its brain. The memory footprint (SRAM, Flash, and EEPROM) of such MCU-based devices is often very limited, restricting onboard Machine Learning (ML) model training for large trainsets with high feature dimensions. To cope with memory issues, the current edge analytics approaches train high-quality ML models on the cloud GPUs (uses large volume historical data), then deploy the deep optimized version of the resultant models on edge devices for inference. Such approaches are inefficient in concept drift situations where the data generated at the device level vary frequently, and trained models are clueless on how to behave if previously unseen data arrives. In this paper, we present Train++, an incremental training algorithm that trains ML models locally at the device level (e.g., on MCUs and small CPUs) using the full n-samples of high-dimensional data. Train++ transforms even the most resource-constrained MCU-based IoT edge devices into intelligent devices that can locally build their own knowledge base on-the-fly using the live data, thus creating smart self-learning and autonomous problem-solving devices. Train++ algorithm is extensively evaluated on 5 popular MCU-boards, using 7 datasets of varying sizes and feature dimensions. A few exciting findings when analyzing the evaluation results are: (i) The proposed method reduces the onboard binary classifier training time by {$\approx$} 10 - 226 sec across various commodity MCUs; (ii) Train++ can infer on MCUs for the entire test set in real-time of 1 ms; (iii) The accuracy improved by 5.15 - 7.3\% since the incremental characteristic of Train++ enabled the loading of full n-samples of the high-dimensional datasets even on MCUs with only a few hundred kBs of memory.},
  keywords = {CT: Framework,Data models,Edge Computing,Embedded systems,Incremental Learning,Inference algorithms,Intelligent Microcontrollers,Online Learning,Optimization,Performance evaluation,Real-time systems,RT: Solution Paper,Solid modeling,Training},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Sudharsan et al. - 2021 - Train++ An Incremental ML Model Training Algorithm to Create Self-Learning IoT Devices.docx;/Users/lukasgrodmeier/Zotero/storage/DRW69B3H/Sudharsan et al. - 2021 - Train++ An Incremental ML Model Training Algorithm to Create Self-Learning IoT Devices.pdf}
}

@article{szydloManagementTinyMLEnabled2024,
  title = {Management of {{TinyML Enabled Internet}} of {{Things Devices}}},
  author = {Szydlo, Tomasz and Nagy, Marcin},
  year = {2024},
  journal = {IEEE Micro},
  pages = {1--7},
  issn = {1937-4143},
  doi = {10.1109/MM.2024.3382488},
  urldate = {2024-12-11},
  abstract = {Internet of Things systems are used in many aspects of our lives. Thanks to TinyML algorithms, they provide several new and smart functionalities that were impossible before. However, implementing such a solution on a large scale and maintaining it over time is a big challenge. This is due to the need not only to update the device firmware to remove errors and extend the functionality of the devices but also to update the ML models. This imposes several requirements for device monitoring and management mechanisms. In this work, we discuss not only the required aspects that an IoT system should meet, but we also show how they fit into the ML model management process.},
  keywords = {CT: Framework,Data models,Fraud,Internet of Things,Microprogramming,Monitoring,Protocols,Random access memory,RT: Solution Paper},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Szydlo und Nagy - 2024 - Management of TinyML Enabled Internet of Things Devices.docx;/Users/lukasgrodmeier/Zotero/storage/YLYCDKUG/Szydlo und Nagy - 2024 - Management of TinyML Enabled Internet of Things Devices.pdf}
}

@article{tekinReviewOndeviceMachine2024,
  title = {A Review of On-Device Machine Learning for {{IoT}}: {{An}} Energy Perspective},
  shorttitle = {A Review of On-Device Machine Learning for {{IoT}}},
  author = {Tekin, Nazli and Aris, Ahmet and Acar, Abbas and Uluagac, Selcuk and Gungor, Vehbi Cagri},
  year = {2024},
  month = feb,
  journal = {Ad Hoc Networks},
  volume = {153},
  pages = {103348},
  issn = {1570-8705},
  doi = {10.1016/j.adhoc.2023.103348},
  urldate = {2024-12-07},
  abstract = {Recently, there has been a substantial interest in on-device Machine Learning (ML) models to provide intelligence for the Internet of Things (IoT) applications such as image classification, human activity recognition, and anomaly detection. Traditionally, ML models are deployed in the cloud or centralized servers to take advantage of their abundant computational resources. However, sharing data with the cloud and third parties degrades privacy and may cause propagation delay in the network due to a large amount of transmitted data impacting the performance of real-time applications. To this end, deploying ML models on-device (i.e., on IoT devices), in which data does not need to be transmitted, becomes imperative. However, deploying and running ML models on already resource-constrained IoT devices is challenging and requires intense energy consumption. Numerous works have been proposed in the literature to address this issue. Although there are considerable works that discuss energy-aware ML approaches for on-device implementation, there remains a gap in the literature on a comprehensive review of this subject. In this paper, we provide a review of existing studies focusing on-device ML models for IoT applications in terms of energy consumption. One of the key contributions of this study is to introduce a taxonomy to define approaches for employing energy-aware on-device ML models on IoT devices in the literature. Based on our review in this paper, our key findings are provided and the open issues that can be investigated further by other researchers are discussed. We believe that this study will be a reference for practitioners and researchers who want to employ energy-aware on-device ML models for IoT applications.},
  keywords = {Deep learning,Edge computing,Energy efficiency,Internet of Things,Machine Learning,Tiny machine learning},
  file = {/Users/lukasgrodmeier/Zotero/storage/S6FDQHPW/Tekin et al. - 2024 - A review of on-device machine learning for IoT An energy perspective.pdf}
}

@article{testiMLOpsTaxonomyMethodology2022,
  title = {{{MLOps}}: {{A Taxonomy}} and a {{Methodology}}},
  shorttitle = {{{MLOps}}},
  author = {Testi, Matteo and Ballabio, Matteo and Frontoni, Emanuele and Iannello, Giulio and Moccia, Sara and Soda, Paolo and Vessio, Gennaro},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {63606--63618},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3181730},
  urldate = {2025-02-08},
  abstract = {Over the past few decades, the substantial growth in enterprise-data availability and the advancements in Artificial Intelligence (AI) have allowed companies to solve real-world problems using Machine Learning (ML). ML Operations (MLOps) represents an effective strategy for bringing ML models from academic resources to useful tools for solving problems in the corporate world. The current literature on MLOps is still mostly disconnected and sporadic. In this work, we review the existing scientific literature and we propose a taxonomy for clustering research papers on MLOps. In addition, we present methodologies and operations aimed at defining an ML pipeline to simplify the release of ML applications in the industry. The pipeline is based on ten steps: business problem understanding, data acquisition, ML methodology, ML training \& testing, continuous integration, continuous delivery, continuous training, continuous monitoring, explainability, and sustainability. The scientific and business interest and the impact of MLOps have grown significantly over the past years: the definition of a clear and standardized methodology for conducting MLOps projects is the main contribution of this paper.},
  keywords = {Automation,Business,continuous delivery,continuous integration,continuous monitoring,continuous training,MLOps,Monitoring,Pipelines,Production,Surgery,sustainability,Training,XAI},
  file = {/Users/lukasgrodmeier/Zotero/storage/TIIQM6ZZ/Testi et al. - 2022 - MLOps A Taxonomy and a Methodology.pdf}
}

@article{tsoukasReviewEmergingTechnology2024,
  title = {A {{Review}} on the Emerging Technology of {{TinyML}}},
  author = {Tsoukas, Vasileios and Gkogkidis, Anargyros and Boumpa, Eleni and Kakarountas, Athanasios},
  year = {2024},
  month = oct,
  journal = {ACM Computing Surveys},
  volume = {56},
  number = {10},
  pages = {1--37},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3661820},
  urldate = {2024-12-21},
  abstract = {Tiny Machine Learning (TinyML) is an emerging technology proposed by the scientific community for developing autonomous and secure devices that can gather, process, and provide results without transferring data to external entities. The technology aims to democratize AI by making it available to more sectors and contribute to the digital revolution of intelligent devices. In this work, a classification of the most common optimization techniques for Neural Network compression is conducted. Additionally, a review of the development boards and TinyML software is presented. Furthermore, the work provides educational resources, a classification of the technology applications, and future directions and concludes with the challenges and considerations.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/IHJRWQB5/Tsoukas et al. - 2024 - A Review on the emerging technology of TinyML.pdf}
}

@inproceedings{tsoukasReviewMachineLearning2022,
  title = {A {{Review}} of {{Machine Learning}} and {{TinyML}} in {{Healthcare}}},
  booktitle = {Proceedings of the 25th {{Pan-Hellenic Conference}} on {{Informatics}}},
  author = {Tsoukas, Vasileios and Boumpa, Eleni and Giannakas, Georgios and Kakarountas, Athanasios},
  year = {2022},
  month = feb,
  series = {{{PCI}} '21},
  pages = {69--73},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3503823.3503836},
  urldate = {2024-12-21},
  abstract = {Healthcare is the field that can benefit from the large amount of raw data generated from portable and wearable devices. This data must be sent to the Cloud for processing due to the computationally intensive nature of current state-of-the-art implementations of Neural Networks. The emerging technology of TinyML is an alternative approach proposed by the scientific community to create autonomous and safe devices that can collect, process, and alert without transmitting data to external entities. This work is the review of the contribution of the emerging technology of TinyML in healthcare applications at the edge, requiring the integration of Machine Learning algorithms, followed by the solutions it can bring, especially in wearable devices. Moreover, it is discussed how TinyML can optimize Neural Networks to bring intelligence and autonomy in devices used in fields such as healthcare.},
  isbn = {978-1-4503-9555-7}
}

@incollection{vombrockeIntroductionDesignScience2020,
  title = {Introduction to {{Design Science Research}}},
  booktitle = {Design {{Science Research}}. {{Cases}}},
  author = {{vom Brocke}, Jan and Hevner, Alan and Maedche, Alexander},
  editor = {{vom Brocke}, Jan and Hevner, Alan and Maedche, Alexander},
  year = {2020},
  pages = {1--13},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-46781-4_1},
  urldate = {2024-12-18},
  abstract = {Design Science Research (DSR) is a problem-solving paradigm that seeks to enhance human knowledge via the creation of innovative artifacts. Simply stated, DSR seeks to enhance technology and science knowledge bases via the creation of innovative artifacts that solve problems and improve the environment in which they are instantiated. The results of DSR include both the newly designed artifacts and design knowledge (DK) that provides a fuller understanding via design theories of why the artifacts enhance (or, disrupt) the relevant application contexts. The goal of this introduction chapter is to provide a brief survey of DSR concepts for better understanding of the following chapters that present DSR case studies.},
  isbn = {978-3-030-46781-4},
  langid = {english}
}

@article{vombrockeStandingShouldersGiants2015,
  title = {Standing on the {{Shoulders}} of {{Giants}}: {{Challenges}} and {{Recommendations}} of {{Literature Search}} in {{Information Systems Research}}},
  shorttitle = {Standing on the {{Shoulders}} of {{Giants}}},
  author = {Vom Brocke, Jan and Simons, Alexander and Riemer, Kai and Niehaves, Bj{\"o}rn and Plattfaut, Ralf and Cleven, Anne},
  year = {2015},
  journal = {Communications of the Association for Information Systems},
  volume = {37},
  issn = {15293181},
  doi = {10.17705/1CAIS.03709},
  urldate = {2024-12-18},
  abstract = {The ``standing on the shoulders of giants'' metaphor is often used to acknowledge the work of others when undertaking research and, in particular, stresses the importance of literature reviews in scientific inquiry. Though the significance of literature reviews has never been in doubt, researchers, especially novice researchers, still struggle with developing effective strategies for reviewing literature. An important reason for this difficulty is the rapidly increasing number of potentially relevant publications---not all of which necessarily add value to a literature review. As such, avoiding standing on the shoulders of dwarfs literature search emerges as a major issue in crafting an effective literature review. In this paper, we discuss challenges of literature searches in the increasingly dynamic context of information systems (IS) research and make recommendations for how to deal with them. We present practical guidelines and a checklist to help researchers with planning and organizing their literature searches.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/EEGI57XY/Vom Brocke et al. - 2015 - Standing on the Shoulders of Giants Challenges and Recommendations of Literature Search in Informat.pdf}
}

@article{websterAnalyzingPrepareFuture2002,
  title = {Analyzing the {{Past}} to {{Prepare}} for the {{Future}}: {{Writing}} a {{Literature Review}}},
  author = {Webster, Jane and Watson, Richard T.},
  year = {2002},
  journal = {MIS Quarterly},
  volume = {26},
  number = {2},
  eprint = {4132319},
  eprinttype = {jstor},
  pages = {xiii-xxiii},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/GWMPT7RL/Webster und Watson - 2002 - Analyzing the Past to Prepare for the Future Writing a Literature Review.pdf}
}

@article{welchGeneralizationStudentsProblem1947,
  title = {The {{Generalization}} of `{{Student}}'s' {{Problem}} When {{Several Different Population Variances}} Are {{Involved}}},
  author = {Welch, B. L.},
  year = {1947},
  journal = {Biometrika},
  volume = {34},
  number = {1/2},
  eprint = {2332510},
  eprinttype = {jstor},
  pages = {28--35},
  publisher = {[Oxford University Press, Biometrika Trust]},
  issn = {0006-3444},
  doi = {10.2307/2332510},
  urldate = {2025-05-28}
}

@article{wieringaRequirementsEngineeringPaper2006,
  title = {Requirements Engineering Paper Classification and Evaluation Criteria: A Proposal and a Discussion},
  shorttitle = {Requirements Engineering Paper Classification and Evaluation Criteria},
  author = {Wieringa, Roel and Maiden, Neil and Mead, Nancy and Rolland, Colette},
  year = {2006},
  month = mar,
  journal = {Requirements Engineering},
  volume = {11},
  number = {1},
  pages = {102--107},
  issn = {0947-3602, 1432-010X},
  doi = {10.1007/s00766-005-0021-6},
  urldate = {2024-12-19},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/BVKRVH5Y/Wieringa et al. - 2006 - Requirements engineering paper classification and evaluation criteria a proposal and a discussion.pdf}
}

@article{wilcoxonIndividualComparisonsRanking1945,
  title = {Individual {{Comparisons}} by {{Ranking Methods}}},
  author = {Wilcoxon, Frank},
  year = {1945},
  journal = {Biometrics Bulletin},
  volume = {1},
  number = {6},
  eprint = {3001968},
  eprinttype = {jstor},
  pages = {80--83},
  publisher = {[International Biometric Society, Wiley]},
  issn = {0099-4987},
  doi = {10.2307/3001968},
  urldate = {2025-05-26}
}

@book{wohlinExperimentationSoftwareEngineering2024,
  title = {Experimentation in {{Software Engineering}}},
  author = {Wohlin, Claes and Runeson, Per and H{\"o}st, Martin and Ohlsson, Magnus C. and Regnell, Bj{\"o}rn and Wessl{\'e}n, Anders},
  year = {2024},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-69306-3},
  urldate = {2025-05-22},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-662-69305-6 978-3-662-69306-3},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/RPDNMZ2I/Wohlin et al. - 2024 - Experimentation in Software Engineering.pdf}
}

@inproceedings{wohlinGuidelinesSnowballingSystematic2014a,
  title = {Guidelines for Snowballing in Systematic Literature Studies and a Replication in Software Engineering},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}}},
  author = {Wohlin, Claes},
  year = {2014},
  month = may,
  pages = {1--10},
  publisher = {ACM},
  address = {London England United Kingdom},
  doi = {10.1145/2601248.2601268},
  urldate = {2024-12-18},
  abstract = {Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably. Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review. Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches. Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review. Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.},
  isbn = {978-1-4503-2476-2},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/CATZH7PH/Wohlin - 2014 - Guidelines for snowballing in systematic literature studies and a replication in software engineerin.pdf}
}

@article{wohlinSuccessfulCombinationDatabase2022,
  title = {Successful Combination of Database Search and Snowballing for Identification of Primary Studies in Systematic Literature Studies},
  author = {Wohlin, Claes and Kalinowski, Marcos and Romero Felizardo, Katia and Mendes, Emilia},
  year = {2022},
  month = jul,
  journal = {Information and Software Technology},
  volume = {147},
  pages = {106908},
  issn = {09505849},
  doi = {10.1016/j.infsof.2022.106908},
  urldate = {2024-12-18},
  abstract = {Background: A good search strategy is essential for a successful systematic literature study. Historically, database searches have been the norm, which was later complemented with snowball searches. Our conjecture is that we can perform even better searches if combining these two search approaches, referred to as a hybrid search strategy. Objective: Our main objective was to compare and evaluate a hybrid search strategy. Furthermore, we compared four alternative hybrid search strategies to assess whether we could identify more cost-efficient ways of searching for relevant primary studies. Methods: To compare and evaluate the hybrid search strategy, we replicated the search procedure in a systematic literature review (SLR) on industry--academia collaboration in software engineering. The SLR used a more ``traditional'' approach to searching for relevant articles for an SLR, while our replication was executed using a hybrid search strategy. Results: In our evaluation, the hybrid search strategy was superior in identifying relevant primary studies. It identified 30\% more primary studies and even more studies when focusing only on peer-reviewed articles. To embrace individual viewpoints when assessing research articles and minimise the risk of missing primary studies, we introduced two new concepts, wild cards and borderline articles, when performing systematic literature studies. Conclusions: The hybrid search strategy is a strong contender for being used when performing systematic literature studies. Furthermore, alternative hybrid search strategies may be viable if selected wisely in relation to the start set for snowballing. Finally, the two new concepts were judged as essential to cater for different individual judgements and to minimise the risk of excluding primary studies that ought to be included.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/9TB44ZWT/Wohlin et al. - 2022 - Successful combination of database search and snowballing for identification of primary studies in s.pdf}
}

@article{wysockiUniversityChicagoBooth,
  title = {University of {{Chicago Booth School}} of {{Business}}, {{NBER}} and {{ECGI}}},
  author = {Wysocki, Peter},
  abstract = {This paper discusses the empirical literature on the economic consequences of disclosure and financial reporting regulation, drawing on U.S. and international evidence. Given the policy relevance of research on regulation, we highlight the challenges with: (i) quantifying regulatory costs and benefits, (ii) measuring disclosure and reporting outcomes, and (iii) drawing causal inferences from regulatory studies. Next, we discuss empirical studies that link disclosure and reporting activities to firm-specific and market-wide economic outcomes. Understanding these links is important when evaluating regulation. We then synthesize the empirical evidence on the economic effects of disclosure regulation and reporting standards, including the evidence on IFRS adoption. Several important conclusions emerge. We generally lack evidence on market-wide effects and externalities from regulation, yet such evidence is central to the economic justification of regulation. Moreover, evidence on causal effects of disclosure and reporting regulation is still relatively rare. We also lack evidence on the real effects of such regulation. These limitations provide many research opportunities. We conclude with several specific suggestions for future research.},
  langid = {english},
  file = {/Users/lukasgrodmeier/Zotero/storage/AF5FBCZN/Wysocki - University of Chicago Booth School of Business, NBER and ECGI.pdf}
}

@article{zaidiUnlockingEdgeIntelligence2022,
  title = {Unlocking {{Edge Intelligence Through Tiny Machine Learning}} ({{TinyML}})},
  author = {Zaidi, Syed Ali Raza and Hayajneh, Ali M. and Hafeez, Maryam and Ahmed, Q. Z.},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {100867--100877},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3207200},
  urldate = {2024-12-14},
  abstract = {Machine Learning (ML) on the edge is key to enabling a new breed of IoT and autonomous system applications. The departure from the traditional cloud-centric architecture means that new deployments can be more power-efficient, provide better privacy and reduce latency for inference. At the core of this paradigm is TinyML, a framework allowing the execution of ML models on low-power embedded devices. TinyML allows importing pre-trained ML models on the edge for providing ML-as-a-Service (MLaaS) to IoT devices. This article presents a TinyMLaaS (TMLaaS) architecture for future IoT deployments. The TMLaaS architecture inherently presents several design trade-offs in terms of energy consumption, security, privacy, and latency. We also present how TMLaaS architecture can be implemented, deployed, and maintained for large-scale IoT deployment. The feasibility of implementation for the TMLaaS architecture has been demonstrated with the help of a case study.},
  keywords = {5G,Cloud computing,Collaborative work,Computational modeling,CT: Framework,deep learning,Deep learning,edge computing,Edge computing,energy efficiency,Energy efficiency,federated learning,gesture recognition,implementation,Internet of Things,IoT,Logic gates,LoRa,Machine learning,Memory management,MLOps,Performance evaluation,RT: Solution Paper,Tiny machine learning,transfer learning,Transfer learning},
  file = {/Users/lukasgrodmeier/Documents/HS Reutlingen/Thesis/03 Auswertung/01 Paper Auswertung/Zaidi et al. - 2022 - Unlocking Edge Intelligence Through Tiny Machine Learning (TinyML).docx;/Users/lukasgrodmeier/Zotero/storage/P45LSZ83/Zaidi et al. - 2022 - Unlocking Edge Intelligence Through Tiny Machine Learning (TinyML).pdf}
}

@article{zhouEdgeIntelligencePaving2019,
  title = {Edge {{Intelligence}}: {{Paving}} the {{Last Mile}} of {{Artificial Intelligence With Edge Computing}}},
  shorttitle = {Edge {{Intelligence}}},
  author = {Zhou, Zhi and Chen, Xu and Li, En and Zeng, Liekang and Luo, Ke and Zhang, Junshan},
  year = {2019},
  month = aug,
  journal = {Proceedings of the IEEE},
  volume = {107},
  number = {8},
  pages = {1738--1762},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2019.2918951},
  urldate = {2024-12-14},
  abstract = {With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI.},
  keywords = {Artificial intelligence,Computational modeling,Computer architecture,deep learning,Deep learning,edge computing,Edge computing,edge intelligence,Task analysis,Training},
  file = {/Users/lukasgrodmeier/Zotero/storage/9WLGAIPT/Zhou et al. - 2019 - Edge Intelligence Paving the Last Mile of Artificial Intelligence With Edge Computing.pdf;/Users/lukasgrodmeier/Zotero/storage/DC7G4Z9G/8736011.html}
}
