%!TEX root = thesis.tex

\chapter{Conclusion}
\label{chp:Conclusion}

This thesis was dedicated to the conception, development, and evaluation of a novel ecosystem for the lifecycle management of machine learning models on severely resource-constrained embedded systems, known as \gls{tinyml}. Stemming from the observation that traditional \gls{mlops} approaches do not adequately address the specific challenges of \gls{tinyml} environments—particularly limited computational power, low memory, scarce energy budgets, and often unreliable network connectivity—a system was designed that aims for maximum on-device autonomy with optional, synergistic server-side support. The original motivation was to reduce dependence on cloud infrastructures, thereby expanding the applicability of \gls{tinyml} in scenarios where continuous cloud connectivity cannot be guaranteed, such as in the motivating context of an autonomous Mars rover mission.

This thesis offers several scientific contributions. The systematic literature analysis provided a detailed overview of the current research landscape in \gls{tinymlops}, highlighting the predominance of centralized training and offline learning, the rise of decentralized and on-device learning strategies, the fragmentation of existing solutions, and the lack of comprehensive, empirically validated end-to-end frameworks for autonomous on-device \gls{lcm}. This review underscored the need for the proposed integrated ecosystem. The core innovative contribution is the conceptual design of the \gls{tinymlops} ecosystem, encompassing \gls{tinylcm} and TinySphere. This design is guided by an ``autonomy-first'' philosophy, featuring a modular, data-centric pipeline architecture for \gls{tinylcm} that includes components for feature extraction, resource-efficient \gls{knn} classification, unsupervised drift detection using the \texttt{KNNDistanceMonitor} and the Page-Hinkley test, robust state management for versioning and rollbacks via the \texttt{AdaptiveStateManager}, and a conceptual mechanism for heuristic-based on-device adaptation involving the \texttt{HeuristicAdapter} and \texttt{QuarantineBuffer}. TinySphere is designed as a specialized, \gls{tinyml}-centric server platform that extends beyond generic \gls{mlops} tools by being tailored to process data from \gls{tinylcm} devices, support validation workflows, and enable comprehensive fleet management, all interacting via an opportunistic client-server model. The empirical validation of \gls{tinylcm} furnished concrete evidence of its feasibility and performance, providing quantitative benchmarks for latency and resource usage on representative \gls{sbc} hardware.

The findings of this research bear significant implications for both scientific inquiry and practical application. The work advances the development of more autonomous \gls{tinyml} systems, reducing their dependence on continuous network connectivity and cloud intervention, which is particularly relevant for applications in remote or challenging environments. The validated unsupervised drift detection mechanism in \gls{tinylcm} offers a tangible tool for a critical \gls{mlops} phase, addressing the common issue of unavailable real-time labels in many \gls{tinyml} deployments. The TinySphere concept provides a blueprint for server-side infrastructure specifically designed to interact with autonomous \gls{tinyml} devices, filling a gap in understanding and supporting their unique data streams and operational modes. The empirically determined performance benchmarks serve as valuable references for assessing the costs and capabilities of on-device \gls{mlops} functions. The tension between maximal on-device autonomy and the benefits of centralized \gls{mlops} is a central theme, and the proposed ecosystem attempts to strike a balance, aiming for an intelligent combination rather than an exclusive choice.